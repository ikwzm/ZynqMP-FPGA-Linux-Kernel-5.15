--- linux-5.15.36/include/linux/mtd/cfi.h	2023-04-14 12:26:11.442580900 +0900
+++ linux-xlnx-2022.2/include/linux/mtd/cfi.h	2023-04-14 12:24:18.739626000 +0900
@@ -373,6 +373,7 @@
 #define CFI_MFR_MICRON		0x002C /* Micron */
 #define CFI_MFR_TOSHIBA		0x0098
 #define CFI_MFR_WINBOND		0x00DA
+#define CFI_MFR_WINBND		0x00EF /* Winbond */
 
 void cfi_fixup(struct mtd_info *mtd, struct cfi_fixup* fixups);
 
--- linux-5.15.36/include/linux/mtd/mtd.h	2023-04-14 12:26:11.442580900 +0900
+++ linux-xlnx-2022.2/include/linux/mtd/mtd.h	2023-04-14 12:24:18.739626000 +0900
@@ -73,7 +73,8 @@
 };
 
 #define MTD_MAX_OOBFREE_ENTRIES_LARGE	32
-#define MTD_MAX_ECCPOS_ENTRIES_LARGE	640
+#define MTD_MAX_ECCPOS_ENTRIES_LARGE	1260
+
 /**
  * struct mtd_oob_region - oob region definition
  * @offset: region offset
--- linux-5.15.36/include/linux/mtd/onfi.h	2023-04-14 12:26:11.458173700 +0900
+++ linux-xlnx-2022.2/include/linux/mtd/onfi.h	2023-04-14 12:24:18.739626000 +0900
@@ -172,6 +172,7 @@
  * @nvddr_timing_modes: Supported source synchronous/NV-DDR timing modes
  * @vendor_revision: Vendor specific revision number
  * @vendor: Vendor specific data
+ * @jedec_id: jedec id of the flash
  */
 struct onfi_params {
 	int version;
@@ -184,6 +185,7 @@
 	u16 nvddr_timing_modes;
 	u16 vendor_revision;
 	u8 vendor[88];
+	u8 jedec_id;
 };
 
 #endif /* __LINUX_MTD_ONFI_H */
--- linux-5.15.36/include/linux/mtd/rawnand.h	2023-04-14 12:26:11.458173700 +0900
+++ linux-xlnx-2022.2/include/linux/mtd/rawnand.h	2023-04-14 12:24:18.755750400 +0900
@@ -1525,6 +1525,10 @@
 int nand_change_read_column_op(struct nand_chip *chip,
 			       unsigned int offset_in_page, void *buf,
 			       unsigned int len, bool force_8bit);
+int nand_check_change_read_column_op(struct nand_chip *chip,
+				     unsigned int offset_in_page, void *buf,
+				     unsigned int len, bool force_8bit,
+				     bool check_only);
 int nand_read_oob_op(struct nand_chip *chip, unsigned int page,
 		     unsigned int offset_in_page, void *buf, unsigned int len);
 int nand_prog_page_begin_op(struct nand_chip *chip, unsigned int page,
--- linux-5.15.36/include/linux/mtd/spi-nor.h	2023-04-14 12:26:11.458173700 +0900
+++ linux-xlnx-2022.2/include/linux/mtd/spi-nor.h	2023-04-14 12:24:18.755750400 +0900
@@ -51,6 +51,7 @@
 #define SPINOR_OP_CLFSR		0x50	/* Clear flag status register */
 #define SPINOR_OP_RDEAR		0xc8	/* Read Extended Address Register */
 #define SPINOR_OP_WREAR		0xc5	/* Write Extended Address Register */
+#define SPINOR_OP_WRCR		0x81	/* Write Configuration register */
 #define SPINOR_OP_SRSTEN	0x66	/* Software Reset Enable */
 #define SPINOR_OP_SRST		0x99	/* Software Reset */
 #define SPINOR_OP_GBULK		0x98    /* Global Block Unlock */
@@ -86,6 +87,7 @@
 #define SPINOR_OP_BP		0x02	/* Byte program */
 #define SPINOR_OP_AAI_WP	0xad	/* Auto address increment word program */
 
+#define GLOBAL_BLKPROT_UNLK	0x98	/* Clear global write protection bits */
 /* Used for S3AN flashes only */
 #define SPINOR_OP_XSE		0x50	/* Sector erase */
 #define SPINOR_OP_XPP		0x82	/* Page program */
@@ -101,6 +103,7 @@
 
 /* Used for Spansion flashes only. */
 #define SPINOR_OP_BRWR		0x17	/* Bank register write */
+#define SPINOR_OP_BRRD		0x16	/* Bank register read */
 #define SPINOR_OP_CLSR		0x30	/* Clear status register 1 */
 
 /* Used for Micron flashes only. */
@@ -119,11 +122,18 @@
 #define SR_BP0			BIT(2)	/* Block protect 0 */
 #define SR_BP1			BIT(3)	/* Block protect 1 */
 #define SR_BP2			BIT(4)	/* Block protect 2 */
-#define SR_BP3			BIT(5)	/* Block protect 3 */
+#define SR_BP_BIT_OFFSET	2	/* Offset to Block protect 0 */
+#define SR_BP_BIT_MASK		(SR_BP2 | SR_BP1 | SR_BP0)
+#define SR_BP3			BIT(6)	/* Block protect 3 */
 #define SR_TB_BIT5		BIT(5)	/* Top/Bottom protect */
 #define SR_BP3_BIT6		BIT(6)	/* Block protect 3 */
+#define SR_BP3_BIT5		BIT(5)	/* Block protect 3 */
 #define SR_TB_BIT6		BIT(6)	/* Top/Bottom protect */
 #define SR_SRWD			BIT(7)	/* SR write protect */
+/* Bit to determine whether protection starts from top or bottom */
+#define SR_BP_TB		0x20
+#define BP_BITS_FROM_SR(sr)	(((sr) & SR_BP_BIT_MASK) >> SR_BP_BIT_OFFSET)
+#define M25P_MAX_LOCKABLE_SECTORS	64
 /* Spansion/Cypress specific status bits */
 #define SR_E_ERR		BIT(5)
 #define SR_P_ERR		BIT(6)
@@ -141,6 +151,8 @@
 #define FSR_P_ERR		BIT(4)	/* Program operation status */
 #define FSR_PT_ERR		BIT(1)	/* Protection error bit */
 
+/* Extended/Bank Address Register bits */
+#define EAR_SEGMENT_MASK	0x7 /* 128 Mb segment mask */
 /* Status Register 2 bits. */
 #define SR2_QUAD_EN_BIT1	BIT(1)
 #define SR2_LB1			BIT(3)	/* Security Register Lock Bit 1 */
@@ -399,6 +411,7 @@
 	struct spi_mem		*spimem;
 	u8			*bouncebuf;
 	size_t			bouncebuf_size;
+	struct spi_device       *spi;
 	const struct flash_info	*info;
 	const struct spi_nor_manufacturer *manufacturer;
 	u32			page_size;
@@ -407,11 +420,19 @@
 	u8			read_opcode;
 	u8			read_dummy;
 	u8			program_opcode;
+	u32			jedec_id;
+	u16			curbank;
+	u16			n_sectors;
+	u32			sector_size;
 	enum spi_nor_protocol	read_proto;
 	enum spi_nor_protocol	write_proto;
 	enum spi_nor_protocol	reg_proto;
 	bool			sst_write_second;
 	u32			flags;
+	bool			shift;
+	bool			isparallel;
+	bool                    isstacked;
+	bool			is_lock;
 	enum spi_nor_cmd_ext	cmd_ext_type;
 	struct sfdp		*sfdp;
 
--- linux-5.15.36/drivers/mtd/chips/cfi_probe.c	2023-04-14 12:26:01.474569500 +0900
+++ linux-xlnx-2022.2/drivers/mtd/chips/cfi_probe.c	2023-04-14 12:24:08.483958700 +0900
@@ -198,6 +198,9 @@
 	__u32 base = 0;
 	int num_erase_regions = cfi_read_query(map, base + (0x10 + 28)*ofs_factor);
 	int i;
+	int extendedId1 = 0;
+	int extendedId2 = 0;
+	int extendedId3 = 0;
 	int addr_unlock1 = 0x555, addr_unlock2 = 0x2AA;
 
 	xip_enable(base, map, cfi);
@@ -222,6 +225,38 @@
 	for (i=0; i<(sizeof(struct cfi_ident) + num_erase_regions * 4); i++)
 		((unsigned char *)cfi->cfiq)[i] = cfi_read_query(map,base + (0x10 + i)*ofs_factor);
 
+	/* Note we put the device back into Read Mode BEFORE going into Auto
+	 * Select Mode, as some devices support nesting of modes, others
+	 * don't. This way should always work.
+	 * On cmdset 0001 the writes of 0xaa and 0x55 are not needed, and
+	 * so should be treated as nops or illegal (and so put the device
+	 * back into Read Mode, which is a nop in this case).
+	 */
+	cfi_send_gen_cmd(0xf0,     0, base, map, cfi, cfi->device_type, NULL);
+	cfi_send_gen_cmd(0xaa, 0x555, base, map, cfi, cfi->device_type, NULL);
+	cfi_send_gen_cmd(0x55, 0x2aa, base, map, cfi, cfi->device_type, NULL);
+	cfi_send_gen_cmd(0x90, 0x555, base, map, cfi, cfi->device_type, NULL);
+	cfi->mfr = cfi_read_query16(map, base);
+	cfi->id = cfi_read_query16(map, base + ofs_factor);
+
+	/* Get device ID cycle 1,2,3 for Numonyx/ST devices */
+	if ((cfi->mfr == CFI_MFR_INTEL || cfi->mfr == CFI_MFR_ST)
+		&& ((cfi->id & 0xff) == 0x7e)
+		&& (le16_to_cpu(cfi->cfiq->P_ID) == 0x0002)) {
+		extendedId1 = cfi_read_query16(map, base + 0x1 * ofs_factor);
+		extendedId2 = cfi_read_query16(map, base + 0xe * ofs_factor);
+		extendedId3 = cfi_read_query16(map, base + 0xf * ofs_factor);
+	}
+
+	/* Get AMD/Spansion extended JEDEC ID */
+	if (cfi->mfr == CFI_MFR_AMD && (cfi->id & 0xff) == 0x7e)
+		cfi->id = cfi_read_query(map, base + 0xe * ofs_factor) << 8 |
+			  cfi_read_query(map, base + 0xf * ofs_factor);
+
+	/* Put it back into Read Mode */
+	cfi_qry_mode_off(base, map, cfi);
+	xip_allowed(base, map);
+
 	/* Do any necessary byteswapping */
 	cfi->cfiq->P_ID = le16_to_cpu(cfi->cfiq->P_ID);
 
@@ -231,6 +266,16 @@
 	cfi->cfiq->InterfaceDesc = le16_to_cpu(cfi->cfiq->InterfaceDesc);
 	cfi->cfiq->MaxBufWriteSize = le16_to_cpu(cfi->cfiq->MaxBufWriteSize);
 
+   /* If the device is a M29EW used in 8-bit mode, adjust buffer size */
+	if ((cfi->cfiq->MaxBufWriteSize > 0x8) && (cfi->mfr == CFI_MFR_INTEL ||
+		 cfi->mfr == CFI_MFR_ST) && (extendedId1 == 0x7E) &&
+		 (extendedId2 == 0x22 || extendedId2 == 0x23 || extendedId2 == 0x28) &&
+		 (extendedId3 == 0x01)) {
+		cfi->cfiq->MaxBufWriteSize = 0x8;
+		pr_warn("Adjusted buffer size on Numonyx flash M29EW family");
+		pr_warn("in 8 bit mode\n");
+    }
+
 #ifdef DEBUG_CFI
 	/* Dump the information therein */
 	print_cfi_ident(cfi->cfiq);
--- linux-5.15.36/drivers/mtd/nand/raw/arasan-nand-controller.c	2023-04-14 12:26:01.537086600 +0900
+++ linux-xlnx-2022.2/drivers/mtd/nand/raw/arasan-nand-controller.c	2023-04-14 12:24:08.530822500 +0900
@@ -347,17 +347,17 @@
 
 	/* Update clock frequency */
 	if (nfc->cur_clk != anand->clk) {
-		clk_disable_unprepare(nfc->controller_clk);
-		ret = clk_set_rate(nfc->controller_clk, anand->clk);
+		clk_disable_unprepare(nfc->bus_clk);
+		ret = clk_set_rate(nfc->bus_clk, anand->clk);
 		if (ret) {
 			dev_err(nfc->dev, "Failed to change clock rate\n");
 			return ret;
 		}
 
-		ret = clk_prepare_enable(nfc->controller_clk);
+		ret = clk_prepare_enable(nfc->bus_clk);
 		if (ret) {
 			dev_err(nfc->dev,
-				"Failed to re-enable the controller clock\n");
+				"Failed to re-enable the bus clock\n");
 			return ret;
 		}
 
@@ -891,6 +891,7 @@
 static int anfc_check_op(struct nand_chip *chip,
 			 const struct nand_operation *op)
 {
+	struct mtd_info *mtd = nand_to_mtd(chip);
 	const struct nand_op_instr *instr;
 	int op_id;
 
@@ -940,6 +941,35 @@
 	    op->instrs[1].type == NAND_OP_DATA_IN_INSTR)
 		return -ENOTSUPP;
 
+	/*
+	 * The controller only supports data payload requests which are a
+	 * multiple of 4. This may confuse the core as the core could request a
+	 * given number of bytes and then another number of bytes without
+	 * re-synchronizing the pointer. In practice, most data accesses are
+	 * 4-byte aligned and thus this is not an issue in practice. However,
+	 * rounding up will not work if we reached the end of the device. Any
+	 * unaligned data request that ends at the device boundary would confuse
+	 * the controller and cannot be performed.
+	 *
+	 * TODO: The nand_op_parser framework should be extended to
+	 * support custom checks on DATA instructions.
+	 */
+	if (op->ninstrs == 4 &&
+	    op->instrs[0].type == NAND_OP_CMD_INSTR &&
+	    op->instrs[1].type == NAND_OP_ADDR_INSTR &&
+	    op->instrs[1].ctx.addr.naddrs == 2 &&
+	    op->instrs[2].type == NAND_OP_CMD_INSTR &&
+	    op->instrs[3].type == NAND_OP_DATA_IN_INSTR) {
+		unsigned int start_off, end_off;
+
+		start_off = (op->instrs[1].ctx.addr.addrs[1] << 8) +
+			    op->instrs[1].ctx.addr.addrs[0];
+		end_off = start_off + round_up(op->instrs[3].ctx.data.len, 4);
+
+		if (end_off >= mtd->writesize + mtd->oobsize)
+			return -ENOTSUPP;
+	}
+
 	return nand_op_parser_exec_op(chip, &anfc_op_parser, op, true);
 }
 
@@ -973,21 +1003,6 @@
 		nvddr = nand_get_nvddr_timings(conf);
 		if (IS_ERR(nvddr))
 			return PTR_ERR(nvddr);
-
-		/*
-		 * The controller only supports data payload requests which are
-		 * a multiple of 4. In practice, most data accesses are 4-byte
-		 * aligned and this is not an issue. However, rounding up will
-		 * simply be refused by the controller if we reached the end of
-		 * the device *and* we are using the NV-DDR interface(!). In
-		 * this situation, unaligned data requests ending at the device
-		 * boundary will confuse the controller and cannot be performed.
-		 *
-		 * This is something that happens in nand_read_subpage() when
-		 * selecting software ECC support and must be avoided.
-		 */
-		if (chip->ecc.engine_type == NAND_ECC_ENGINE_TYPE_SOFT)
-			return -ENOTSUPP;
 	} else {
 		sdr = nand_get_sdr_timings(conf);
 		if (IS_ERR(sdr))
@@ -1043,7 +1058,13 @@
 				 DQS_BUFF_SEL_OUT(dqs_mode);
 	}
 
-	anand->clk = ANFC_XLNX_SDR_DFLT_CORE_CLK;
+	if (nand_interface_is_sdr(conf)) {
+		anand->clk = ANFC_XLNX_SDR_DFLT_CORE_CLK;
+	} else {
+		/* ONFI timings are defined in picoseconds */
+		anand->clk = div_u64((u64)NSEC_PER_SEC * 1000,
+				     conf->timings.nvddr.tCK_min);
+	}
 
 	/*
 	 * Due to a hardware bug in the ZynqMP SoC, SDR timing modes 0-1 work
--- linux-5.15.36/drivers/mtd/nand/raw/nand_base.c	2023-04-14 12:26:01.568299300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/nand/raw/nand_base.c	2023-04-14 12:24:08.655764600 +0900
@@ -450,9 +450,11 @@
 	 * if we don't do this. I have no clue why, but I seem to have 'fixed'
 	 * it in the doc2000 driver in August 1999.  dwmw2.
 	 */
-	ret = nand_reset(chip, chipnr);
-	if (ret)
-		return ret;
+	if (chip->parameters.onfi->jedec_id == NAND_MFR_TOSHIBA) {
+		ret = nand_reset(chip, chipnr);
+		if (ret)
+			return ret;
+	}
 
 	nand_select_target(chip, chipnr);
 
@@ -1314,6 +1316,15 @@
 			       unsigned int offset_in_page, void *buf,
 			       unsigned int len, bool force_8bit)
 {
+	return nand_check_change_read_column_op(chip, offset_in_page, buf,
+						len, force_8bit, false);
+}
+
+int nand_check_change_read_column_op(struct nand_chip *chip,
+				     unsigned int offset_in_page, void *buf,
+				     unsigned int len, bool force_8bit,
+				     bool check_only)
+{
 	struct mtd_info *mtd = nand_to_mtd(chip);
 
 	if (len && !buf)
@@ -1350,9 +1361,15 @@
 
 		instrs[3].ctx.data.force_8bit = force_8bit;
 
+		if (check_only)
+			return nand_check_op(chip, &op);
+
 		return nand_exec_op(chip, &op);
 	}
 
+	if (check_only)
+		return 0;
+
 	chip->legacy.cmdfunc(chip, NAND_CMD_RNDOUT, offset_in_page, -1);
 	if (len)
 		chip->legacy.read_buf(chip, buf, len);
@@ -3051,10 +3068,19 @@
 		    (busw - 1))
 			aligned_len++;
 
-		ret = nand_change_read_column_op(chip,
-						 mtd->writesize + aligned_pos,
-						 &chip->oob_poi[aligned_pos],
-						 aligned_len, false);
+		ret = nand_check_change_read_column_op(chip,
+						       mtd->writesize + aligned_pos,
+						       &chip->oob_poi[aligned_pos],
+						       aligned_len, false, true);
+		if (!ret)
+			ret = nand_change_read_column_op(chip,
+							 mtd->writesize + aligned_pos,
+							 &chip->oob_poi[aligned_pos],
+							 aligned_len, false);
+		else
+			ret = nand_change_read_column_op(chip, mtd->writesize,
+							 chip->oob_poi,
+							 mtd->oobsize, false);
 		if (ret)
 			return ret;
 	}
--- linux-5.15.36/drivers/mtd/nand/raw/nand_onfi.c	2023-04-14 12:26:01.568299300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/nand/raw/nand_onfi.c	2023-04-14 12:24:08.655764600 +0900
@@ -319,6 +319,7 @@
 	onfi->sdr_timing_modes = le16_to_cpu(p->sdr_timing_modes);
 	if (le16_to_cpu(p->features) & ONFI_FEATURE_NV_DDR)
 		onfi->nvddr_timing_modes = le16_to_cpu(p->nvddr_timing_modes);
+	onfi->jedec_id = le16_to_cpu(p->jedec_id);
 	onfi->vendor_revision = le16_to_cpu(p->vendor_revision);
 	memcpy(onfi->vendor, p->vendor, sizeof(p->vendor));
 	chip->parameters.onfi = onfi;
--- linux-5.15.36/drivers/mtd/spi-nor/core.c	2023-04-14 12:26:01.615165300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/spi-nor/core.c	2023-04-14 12:24:08.702628500 +0900
@@ -276,7 +276,7 @@
 	if (spi_nor_spimem_bounce(nor, &op))
 		memcpy(nor->bouncebuf, buf, op.data.nbytes);
 
-	if (nor->dirmap.wdesc) {
+	if (nor->dirmap.wdesc && !(nor->info->flags & SST_WRITE)) {
 		nbytes = spi_mem_dirmap_write(nor->dirmap.wdesc, op.addr.val,
 					      op.data.nbytes, op.data.buf.out);
 	} else {
@@ -380,13 +380,15 @@
 int spi_nor_read_sr(struct spi_nor *nor, u8 *sr)
 {
 	int ret;
+	int len;
 
+	nor->isparallel ? (len = 2) : (len = 1);
 	if (nor->spimem) {
 		struct spi_mem_op op =
 			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDSR, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
-				   SPI_MEM_OP_DATA_IN(1, sr, 0));
+				   SPI_MEM_OP_DATA_IN(len, sr, 0));
 
 		if (nor->reg_proto == SNOR_PROTO_8_8_8_DTR) {
 			op.addr.nbytes = nor->params->rdsr_addr_nbytes;
@@ -403,12 +405,15 @@
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
 		ret = spi_nor_controller_ops_read_reg(nor, SPINOR_OP_RDSR, sr,
-						      1);
+						      len);
 	}
 
 	if (ret)
 		dev_dbg(nor->dev, "error %d reading SR\n", ret);
 
+	if (nor->isparallel)
+		sr[0] |= sr[1];
+
 	return ret;
 }
 
@@ -424,13 +429,15 @@
 static int spi_nor_read_fsr(struct spi_nor *nor, u8 *fsr)
 {
 	int ret;
+	int len;
 
+	nor->isparallel ? (len = 2) : (len = 1);
 	if (nor->spimem) {
 		struct spi_mem_op op =
 			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDFSR, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
-				   SPI_MEM_OP_DATA_IN(1, fsr, 0));
+				   SPI_MEM_OP_DATA_IN(len, fsr, 0));
 
 		if (nor->reg_proto == SNOR_PROTO_8_8_8_DTR) {
 			op.addr.nbytes = nor->params->rdsr_addr_nbytes;
@@ -447,12 +454,15 @@
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
 		ret = spi_nor_controller_ops_read_reg(nor, SPINOR_OP_RDFSR, fsr,
-						      1);
+						      len);
 	}
 
 	if (ret)
 		dev_dbg(nor->dev, "error %d reading FSR\n", ret);
 
+	if (nor->isparallel)
+		fsr[0] &= fsr[1];
+
 	return ret;
 }
 
@@ -567,19 +577,46 @@
 /**
  * spi_nor_write_ear() - Write Extended Address Register.
  * @nor:	pointer to 'struct spi_nor'.
- * @ear:	value to write to the Extended Address Register.
+ * @addr:	value to write to the Extended Address Register.
  *
  * Return: 0 on success, -errno otherwise.
  */
-int spi_nor_write_ear(struct spi_nor *nor, u8 ear)
+int spi_nor_write_ear(struct spi_nor *nor, u32 addr)
 {
+	u8 code = SPINOR_OP_WREAR;
+	u32 ear;
 	int ret;
+	struct mtd_info *mtd = &nor->mtd;
+
+	/* Wait until finished previous write command. */
+	if (spi_nor_wait_till_ready(nor))
+		return 1;
+
+	if (mtd->size <= (0x1000000) << nor->shift)
+		return 0;
+
+	addr = addr % (u32)mtd->size;
+	ear = addr >> 24;
 
+	if (!nor->isstacked && ear == nor->curbank)
+		return 0;
+
+	if (nor->isstacked && mtd->size <= 0x2000000)
+		return 0;
+
+	if (nor->jedec_id == CFI_MFR_AMD)
+		code = SPINOR_OP_BRWR;
+	if (nor->jedec_id == CFI_MFR_ST ||
+	    nor->jedec_id == CFI_MFR_MACRONIX ||
+	    nor->jedec_id == CFI_MFR_PMC) {
+		spi_nor_write_enable(nor);
+		code = SPINOR_OP_WREAR;
+	}
 	nor->bouncebuf[0] = ear;
 
 	if (nor->spimem) {
 		struct spi_mem_op op =
-			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_WREAR, 0),
+			SPI_MEM_OP(SPI_MEM_OP_CMD(code, 0),
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
 				   SPI_MEM_OP_DATA_OUT(1, nor->bouncebuf, 0));
@@ -588,12 +625,12 @@
 
 		ret = spi_mem_exec_op(nor->spimem, &op);
 	} else {
-		ret = spi_nor_controller_ops_write_reg(nor, SPINOR_OP_WREAR,
-						       nor->bouncebuf, 1);
+		ret = spi_nor_controller_ops_write_reg(nor, code, nor->bouncebuf, 1);
+		if (ret < 0)
+			return ret;
 	}
 
-	if (ret)
-		dev_dbg(nor->dev, "error %d writing EAR\n", ret);
+	nor->curbank = ear;
 
 	return ret;
 }
@@ -632,6 +669,49 @@
 }
 
 /**
+ * read_ear - Get the extended/bank address register value
+ * @nor:	Pointer to the flash control structure
+ *
+ * This routine reads the Extended/bank address register value
+ *
+ * Return:	Negative if error occurred.
+ */
+static int read_ear(struct spi_nor *nor, struct flash_info *info)
+{
+	int ret;
+	u8 code;
+
+	/* This is actually Spansion */
+	if (nor->jedec_id == CFI_MFR_AMD)
+		code = SPINOR_OP_BRRD;
+	/* This is actually Micron */
+	else if (nor->jedec_id == CFI_MFR_ST ||
+		 nor->jedec_id == CFI_MFR_MACRONIX ||
+		 nor->jedec_id == CFI_MFR_PMC)
+		code = SPINOR_OP_RDEAR;
+	else
+		return -EINVAL;
+	if (nor->spimem) {
+		struct spi_mem_op op =
+			SPI_MEM_OP(SPI_MEM_OP_CMD(code, 1),
+				   SPI_MEM_OP_NO_ADDR,
+				   SPI_MEM_OP_NO_DUMMY,
+				   SPI_MEM_OP_DATA_IN(1, nor->bouncebuf, 1));
+
+		ret = spi_mem_exec_op(nor->spimem, &op);
+	} else {
+		ret = nor->controller_ops->read_reg(nor, code, nor->bouncebuf, 1);
+	}
+	if (ret < 0) {
+		pr_err("error %d reading EAR\n", ret);
+		return ret;
+	}
+
+	return nor->bouncebuf[0];
+}
+
+
+/**
  * spi_nor_xsr_ready() - Query the Status Register of the S3AN flash to see if
  * the flash is ready for new commands.
  * @nor:	pointer to 'struct spi_nor'.
@@ -1185,10 +1265,24 @@
 				   SPI_MEM_OP_NO_ADDR,
 				   SPI_MEM_OP_NO_DUMMY,
 				   SPI_MEM_OP_NO_DATA);
+		if (nor->isstacked)
+			nor->spimem->spi->master->flags &= ~SPI_MASTER_U_PAGE;
 
 		spi_nor_spimem_setup_op(nor, &op, nor->write_proto);
 
 		ret = spi_mem_exec_op(nor->spimem, &op);
+		if (ret)
+			return ret;
+
+		if (nor->isstacked) {
+			/* Wait until previous write command finished */
+			ret = spi_nor_wait_till_ready(nor);
+			if (ret)
+				return ret;
+			nor->spimem->spi->master->flags |= SPI_MASTER_U_PAGE;
+			ret = spi_mem_exec_op(nor->spimem, &op);
+			nor->spimem->spi->master->flags &= ~SPI_MASTER_U_PAGE;
+		}
 	} else {
 		ret = spi_nor_controller_ops_write_reg(nor,
 						       SPINOR_OP_CHIP_ERASE,
@@ -1267,6 +1361,21 @@
 
 static void spi_nor_set_4byte_opcodes(struct spi_nor *nor)
 {
+	u32 sector_size = nor->info->sector_size;
+
+	/* Do some manufacturer fixups first */
+	switch (nor->jedec_id) {
+	case CFI_MFR_AMD:
+		/* No small sector erase for 4-byte command set */
+		nor->erase_opcode = SPINOR_OP_SE;
+		if (nor->isparallel)
+			sector_size <<= 1;
+
+		nor->mtd.erasesize = sector_size;
+		break;
+	default:
+		break;
+	}
 	nor->read_opcode = spi_nor_convert_3to4_read(nor->read_opcode);
 	nor->program_opcode = spi_nor_convert_3to4_program(nor->program_opcode);
 	nor->erase_opcode = spi_nor_convert_3to4_erase(nor->erase_opcode);
@@ -1644,7 +1753,7 @@
 static int spi_nor_erase(struct mtd_info *mtd, struct erase_info *instr)
 {
 	struct spi_nor *nor = mtd_to_spi_nor(mtd);
-	u32 addr, len;
+	u32 addr, len, offset;
 	uint32_t rem;
 	int ret;
 
@@ -1664,6 +1773,8 @@
 	if (ret)
 		return ret;
 
+	reinit_completion(&nor->spimem->request_completion);
+
 	/* whole-chip erase? */
 	if (len == mtd->size && !(nor->flags & SNOR_F_NO_OP_CHIP_ERASE)) {
 		unsigned long timeout;
@@ -1700,8 +1811,33 @@
 			ret = spi_nor_write_enable(nor);
 			if (ret)
 				goto erase_err;
+			offset = addr;
+			if (nor->isparallel == 1)
+				offset /= 2;
+			if (nor->isstacked == 1) {
+				if (offset >= (mtd->size / 2)) {
+					offset = offset - (mtd->size / 2);
+					nor->spimem->spi->master->flags |=
+						SPI_MASTER_U_PAGE;
+				} else {
+					nor->spimem->spi->master->flags &=
+						~SPI_MASTER_U_PAGE;
+				}
+			}
+			if (nor->addr_width == 3) {
+				/* Update Extended Address Register */
+				ret = spi_nor_write_ear(nor, offset);
+				if (ret)
+					goto erase_err;
+			}
+			ret = spi_nor_wait_till_ready(nor);
+			if (ret)
+				goto erase_err;
 
-			ret = spi_nor_erase_sector(nor, addr);
+			ret = spi_nor_write_enable(nor);
+			if (ret)
+				goto erase_err;
+			ret = spi_nor_erase_sector(nor, offset);
 			if (ret)
 				goto erase_err;
 
@@ -1723,6 +1859,8 @@
 	ret = spi_nor_write_disable(nor);
 
 erase_err:
+	complete(&nor->spimem->request_completion);
+
 	spi_nor_unlock_and_unprep(nor);
 
 	return ret;
@@ -1887,6 +2025,9 @@
 		return ERR_PTR(ret);
 	}
 
+	for (i = 0; i < SPI_NOR_MAX_ID_LEN; i++)
+		nor->spimem->device_id[i] = id[i];
+
 	for (i = 0; i < ARRAY_SIZE(manufacturers); i++) {
 		info = spi_nor_search_part_by_id(manufacturers[i]->parts,
 						 manufacturers[i]->nparts,
@@ -1907,19 +2048,107 @@
 {
 	struct spi_nor *nor = mtd_to_spi_nor(mtd);
 	ssize_t ret;
+	u32 offset = from;
+	u32 stack_shift = 0;
+	u32 read_len = 0;
+	u32 rem_bank_len = 0;
+	u8 bank;
+	u8 cur_bank;
+	u8 nxt_bank;
+	u32 bank_size;
 
+#define OFFSET_16_MB 0x1000000
 	dev_dbg(nor->dev, "from 0x%08x, len %zd\n", (u32)from, len);
+	if (nor->isparallel && (from & 1)) {
+		u8 two[2];
+		size_t local_retlen;
 
+		ret = spi_nor_read(mtd, (from & ~1), 2, &local_retlen, two);
+		if (ret < 0)
+			return ret;
+		buf[0] = two[1]; /* copy odd byte to buffer */
+		++buf;
+		*retlen += 1; /* We've read only one actual byte */
+		--len;
+		++from;
+	}
 	ret = spi_nor_lock_and_prep(nor);
 	if (ret)
 		return ret;
 
+	reinit_completion(&nor->spimem->request_completion);
+
 	while (len) {
-		loff_t addr = from;
+		if (nor->addr_width == 3) {
+			bank = (u32)from / (OFFSET_16_MB << nor->shift);
+			rem_bank_len = ((OFFSET_16_MB << nor->shift) *
+							(bank + 1)) - from;
+		}
+		offset = from;
+		if (nor->isparallel == 1)
+			offset /= 2;
+		if (nor->isstacked == 1) {
+			stack_shift = 1;
+			if (offset >= (mtd->size / 2)) {
+				offset = offset - (mtd->size / 2);
+				nor->spimem->spi->master->flags |=
+					SPI_MASTER_U_PAGE;
+			} else {
+				nor->spimem->spi->master->flags &=
+					~SPI_MASTER_U_PAGE;
+			}
+		}
+		if (nor->addr_width == 4) {
+			/*
+			 * Some flash devices like N25Q512 have multiple dies
+			 * in it. Read operation in these devices is bounded
+			 * by its die segment. In a continuous read, across
+			 * multiple dies, when the last byte of the selected
+			 * die segment is read, the next byte read is the
+			 * first byte of the same die segment. This is Die
+			 * cross over issue. So to handle this issue, split
+			 * a read transaction, that spans across multiple
+			 * banks, into one read per bank. Bank size is 16MB
+			 * for single and dual stacked mode and 32MB for dual
+			 * parallel mode.
+			 */
+			if (nor->spi && nor->spi->multi_die) {
+				bank_size = (OFFSET_16_MB << nor->shift);
+				cur_bank = offset / bank_size;
+				nxt_bank = (offset + len) / bank_size;
+				if (cur_bank != nxt_bank)
+					rem_bank_len = ((bank_size *
+							(cur_bank + 1)) -
+							offset) << nor->shift;
+				else
+					rem_bank_len = (mtd->size >>
+							stack_shift) -
+							(offset << nor->shift);
+			} else {
+				rem_bank_len = (mtd->size >> stack_shift) -
+						(offset << nor->shift);
+			}
+		}
+		if (nor->addr_width == 3) {
+			ret = spi_nor_write_ear(nor, offset);
+			if (ret) {
+				dev_err(nor->dev, "While writing ear register\n");
+				goto read_err;
+			}
+		}
+		if (len < rem_bank_len)
+			read_len = len;
+		else
+			read_len = rem_bank_len;
 
-		addr = spi_nor_convert_addr(nor, addr);
+		/* Wait till previous write/erase is done. */
+		ret = spi_nor_wait_till_ready(nor);
+		if (ret)
+			goto read_err;
+
+		offset = spi_nor_convert_addr(nor, offset);
 
-		ret = spi_nor_read_data(nor, addr, len, buf);
+		ret = spi_nor_read_data(nor, (offset), read_len, buf);
 		if (ret == 0) {
 			/* We shouldn't see 0-length reads */
 			ret = -EIO;
@@ -1937,6 +2166,7 @@
 	ret = 0;
 
 read_err:
+	complete(&nor->spimem->request_completion);
 	spi_nor_unlock_and_unprep(nor);
 	return ret;
 }
@@ -1952,17 +2182,45 @@
 	struct spi_nor *nor = mtd_to_spi_nor(mtd);
 	size_t page_offset, page_remain, i;
 	ssize_t ret;
+	u32 offset, stack_shift = 0;
+	u8 bank = 0;
+	u32 rem_bank_len = 0;
 
+#define OFFSET_16_MB 0x1000000
 	dev_dbg(nor->dev, "to 0x%08x, len %zd\n", (u32)to, len);
+	/*
+	 * Cannot write to odd offset in parallel mode,
+	 * so write 2 bytes first
+	 */
+	if (nor->isparallel && (to & 1)) {
+		u8 two[2] = {0xff, buf[0]};
+		size_t local_retlen;
+
+		ret = spi_nor_write(mtd, to & ~1, 2, &local_retlen, two);
+		if (ret < 0)
+			return ret;
+
+		*retlen += 1; /* We've written only one actual byte */
+		++buf;
+		--len;
+		++to;
+	}
 
 	ret = spi_nor_lock_and_prep(nor);
 	if (ret)
 		return ret;
 
+	reinit_completion(&nor->spimem->request_completion);
+
 	for (i = 0; i < len; ) {
 		ssize_t written;
 		loff_t addr = to + i;
 
+		if (nor->addr_width == 3) {
+			bank = (u32)to / (OFFSET_16_MB << nor->shift);
+			rem_bank_len = ((OFFSET_16_MB << nor->shift) *
+							(bank + 1)) - to;
+		}
 		/*
 		 * If page_size is a power of two, the offset can be quickly
 		 * calculated with an AND operation. On the other cases we
@@ -1975,17 +2233,62 @@
 
 			page_offset = do_div(aux, nor->page_size);
 		}
-		/* the size of data remaining on the first page */
-		page_remain = min_t(size_t,
-				    nor->page_size - page_offset, len - i);
+		offset = (to + i);
+		if (nor->isparallel == 1)
+			offset /= 2;
+
+		if (nor->isstacked == 1) {
+			stack_shift = 1;
+			if (offset >= (mtd->size / 2)) {
+				offset = offset - (mtd->size / 2);
+				nor->spimem->spi->master->flags |=
+					SPI_MASTER_U_PAGE;
+			} else {
+				nor->spimem->spi->master->flags &=
+					~SPI_MASTER_U_PAGE;
+			}
+		}
 
-		addr = spi_nor_convert_addr(nor, addr);
+		/* Die cross over issue is not handled */
+		if (nor->addr_width == 4)
+			rem_bank_len = (mtd->size >> stack_shift) - offset;
+		if (nor->addr_width == 3) {
+			ret = spi_nor_write_ear(nor, offset);
+			if (ret) {
+				dev_err(nor->dev, "While writing ear register\n");
+				goto write_err;
+			}
+		}
+		if (nor->isstacked == 1) {
+			if ((len - i) <= rem_bank_len) {
+				page_remain = min_t(size_t,
+						    nor->page_size -
+						    page_offset, len - i);
+			} else {
+				/*
+				 * the size of data remaining
+				 * on the first page
+				 */
+				page_remain = min_t(size_t,
+						    nor->page_size -
+						    page_offset, rem_bank_len);
+			}
+		} else {
+			page_remain = min_t(size_t,
+					    nor->page_size -
+					    page_offset, len - i);
+		}
+		ret = spi_nor_wait_till_ready(nor);
+		if (ret)
+			goto write_err;
+
+		offset = spi_nor_convert_addr(nor, offset);
 
 		ret = spi_nor_write_enable(nor);
 		if (ret)
 			goto write_err;
 
-		ret = spi_nor_write_data(nor, addr, page_remain, buf + i);
+		ret = spi_nor_write_data(nor, (offset), page_remain, buf + i);
 		if (ret < 0)
 			goto write_err;
 		written = ret;
@@ -1995,9 +2298,17 @@
 			goto write_err;
 		*retlen += written;
 		i += written;
+		if (written != page_remain) {
+			dev_err(nor->dev,
+				"While writing %zu bytes written %zd bytes\n",
+				page_remain, written);
+			ret = -EIO;
+			goto write_err;
+		}
 	}
 
 write_err:
+	complete(&nor->spimem->request_completion);
 	spi_nor_unlock_and_unprep(nor);
 	return ret;
 }
@@ -2230,7 +2541,7 @@
 	erase->size = size;
 	erase->opcode = opcode;
 	/* JEDEC JESD216B Standard imposes erase sizes to be power of 2. */
-	erase->size_shift = ffs(erase->size) - 1;
+	erase->size_shift = erase->size ? (ffs(erase->size) - 1) : 0;
 	erase->size_mask = (1 << erase->size_shift) - 1;
 }
 
@@ -2383,6 +2694,12 @@
 	u32 wanted_size = nor->info->sector_size;
 	int i;
 
+	if (nor->isparallel)
+		wanted_size <<= 1;
+
+	if (mtd->erasesize &&
+	    nor->jedec_id != CFI_MFR_AMD)
+		return 0;
 	/*
 	 * The previous implementation handling Sector Erase commands assumed
 	 * that the SPI flash memory has an uniform layout then used only one
@@ -2402,6 +2719,9 @@
 			return -EINVAL;
 		nor->erase_opcode = erase->opcode;
 		mtd->erasesize = erase->size;
+		if (nor->shift)
+			mtd->erasesize = mtd->erasesize << nor->shift;
+
 		return 0;
 	}
 
@@ -2541,6 +2861,9 @@
 	const struct flash_info *info = nor->info;
 	struct device_node *np = spi_nor_get_flash_node(nor);
 	u8 i, erase_mask;
+	u32 n_sectors = info->n_sectors;
+	u32 sector_size = info->sector_size;
+	u32 page_size = info->page_size;
 
 	/* Initialize default flash parameters and settings. */
 	params->quad_enable = spi_nor_sr2_bit1_quad_enable;
@@ -2553,8 +2876,16 @@
 
 	/* Set SPI NOR sizes. */
 	params->writesize = 1;
-	params->size = (u64)info->sector_size * info->n_sectors;
-	params->page_size = info->page_size;
+	if (nor->isstacked)
+		n_sectors <<= 1;
+
+	if (nor->isparallel) {
+		sector_size <<= 1;
+		page_size <<= 1;
+	}
+
+	params->size = (u64)sector_size * n_sectors;
+	params->page_size = page_size;
 
 	if (!(info->flags & SPI_NOR_NO_FR)) {
 		/* Default to Fast Read for DT and non-DT platform devices. */
@@ -2637,7 +2968,7 @@
 		i++;
 	}
 	erase_mask |= BIT(i);
-	spi_nor_set_erase_type(&map->erase_type[i], info->sector_size,
+	spi_nor_set_erase_type(&map->erase_type[i], sector_size,
 			       SPINOR_OP_SE);
 	spi_nor_init_uniform_erase_map(map, erase_mask, params->size);
 }
@@ -2758,10 +3089,21 @@
 	if (!(nor->flags & SNOR_F_IO_MODE_EN_VOLATILE))
 		return 0;
 
+	if (nor->isstacked)
+		nor->spimem->spi->master->flags &= ~SPI_MASTER_U_PAGE;
+
 	ret = nor->params->octal_dtr_enable(nor, enable);
 	if (ret)
 		return ret;
 
+	if (nor->isstacked) {
+		nor->spimem->spi->master->flags |= SPI_MASTER_U_PAGE;
+		ret = nor->params->octal_dtr_enable(nor, enable);
+		nor->spimem->spi->master->flags &= ~SPI_MASTER_U_PAGE;
+		if (ret)
+			return ret;
+	}
+
 	if (enable)
 		nor->reg_proto = SNOR_PROTO_8_8_8_DTR;
 	else
@@ -2778,6 +3120,8 @@
  */
 static int spi_nor_quad_enable(struct spi_nor *nor)
 {
+	int err;
+
 	if (!nor->params->quad_enable)
 		return 0;
 
@@ -2785,13 +3129,28 @@
 	      spi_nor_get_protocol_width(nor->write_proto) == 4))
 		return 0;
 
-	return nor->params->quad_enable(nor);
+	err = nor->params->quad_enable(nor);
+	if (nor->isstacked) {
+		nor->spimem->spi->master->flags |= SPI_MASTER_U_PAGE;
+		err = nor->params->quad_enable(nor);
+		nor->spimem->spi->master->flags &= ~SPI_MASTER_U_PAGE;
+	}
+	return err;
 }
 
 static int spi_nor_init(struct spi_nor *nor)
 {
 	int err;
 
+	if (nor->jedec_id == CFI_MFR_ATMEL ||
+	    nor->jedec_id == CFI_MFR_INTEL ||
+	    nor->jedec_id == CFI_MFR_SST ||
+	    nor->flags & SNOR_F_HAS_LOCK) {
+		spi_nor_write_enable(nor);
+		nor->bouncebuf[0] = 0;
+		spi_nor_write_sr(nor, nor->bouncebuf, 1);
+	}
+
 	err = spi_nor_octal_dtr_enable(nor, true);
 	if (err) {
 		dev_dbg(nor->dev, "octal mode not supported\n");
@@ -2832,6 +3191,11 @@
 		WARN_ONCE(nor->flags & SNOR_F_BROKEN_RESET,
 			  "enabling reset hack; may not recover from unexpected reboots\n");
 		nor->params->set_4byte_addr_mode(nor, true);
+		if (nor->isstacked) {
+			nor->spimem->spi->master->flags |= SPI_MASTER_U_PAGE;
+			nor->params->set_4byte_addr_mode(nor, true);
+			nor->spimem->spi->master->flags &= ~SPI_MASTER_U_PAGE;
+		}
 	}
 
 	return 0;
@@ -2952,8 +3316,10 @@
 void spi_nor_restore(struct spi_nor *nor)
 {
 	/* restore the addressing mode */
-	if (nor->addr_width == 4 && !(nor->flags & SNOR_F_4B_OPCODES) &&
-	    nor->flags & SNOR_F_BROKEN_RESET)
+	if (nor->addr_width == 4 && !(nor->info->flags & SNOR_F_4B_OPCODES) &&
+	    (nor->flags & SNOR_F_BROKEN_RESET) &&
+	    (nor->jedec_id != CFI_MFR_AMD) &&
+	    !(nor->info->flags & SPI_NOR_4B_OPCODES))
 		nor->params->set_4byte_addr_mode(nor, false);
 
 	if (nor->flags & SNOR_F_SOFT_RESET)
@@ -2980,6 +3346,8 @@
 
 static int spi_nor_set_addr_width(struct spi_nor *nor)
 {
+	struct device_node *np = spi_nor_get_flash_node(nor);
+	struct device_node *np_spi;
 	if (nor->addr_width) {
 		/* already configured from SFDP */
 	} else if (nor->read_proto == SNOR_PROTO_8_8_8_DTR) {
@@ -3002,9 +3370,66 @@
 		nor->addr_width = 3;
 	}
 
-	if (nor->addr_width == 3 && nor->mtd.size > 0x1000000) {
-		/* enable 4-byte addressing if the device exceeds 16MiB */
-		nor->addr_width = 4;
+	if (nor->addr_width == 3 && (nor->mtd.size >> nor->shift) > 0x1000000) {
+#ifdef CONFIG_OF
+		np_spi = of_get_next_parent(np);
+		if (of_property_match_string(np_spi, "compatible",
+					     "xlnx,zynq-qspi-1.0") >= 0) {
+			int status;
+
+			nor->addr_width = 3;
+			nor->params->set_4byte_addr_mode(nor, false);
+			if (nor->isstacked) {
+				nor->spimem->spi->master->flags |=
+					SPI_MASTER_U_PAGE;
+				nor->params->set_4byte_addr_mode(nor, false);
+				nor->spimem->spi->master->flags &=
+					~SPI_MASTER_U_PAGE;
+			}
+			status = read_ear(nor, (struct flash_info *)nor->info);
+			if (status < 0)
+				dev_warn(nor->dev, "failed to read ear reg\n");
+			else
+				nor->curbank = status & EAR_SEGMENT_MASK;
+		} else {
+#endif
+			/*
+			 * enable 4-byte addressing if the
+			 * device exceeds 16MiB
+			 */
+			nor->addr_width = 4;
+			if (nor->jedec_id == CFI_MFR_AMD ||
+			    nor->info->flags & SPI_NOR_4B_OPCODES) {
+				spi_nor_set_4byte_opcodes(nor);
+				nor->params->set_4byte_addr_mode(nor, true);
+				if (nor->isstacked) {
+					nor->spimem->spi->master->flags |=
+					SPI_MASTER_U_PAGE;
+					nor->params->set_4byte_addr_mode(nor, true);
+					nor->spimem->spi->master->flags &=
+					~SPI_MASTER_U_PAGE;
+				}
+			} else {
+				np_spi = of_get_next_parent(np);
+				if (of_property_match_string(np_spi,
+							     "compatible",
+							     "xlnx,xps-spi-2.00.a") >= 0) {
+					nor->addr_width = 3;
+					nor->params->set_4byte_addr_mode(nor, false);
+				} else {
+					nor->params->set_4byte_addr_mode(nor, true);
+					if (nor->isstacked) {
+						nor->spimem->spi->master->flags |=
+							SPI_MASTER_U_PAGE;
+						nor->params->set_4byte_addr_mode(nor, true);
+						nor->spimem->spi->master->flags &=
+							~SPI_MASTER_U_PAGE;
+					}
+				}
+			}
+#ifdef CONFIG_OF
+		}
+#endif
 	}
 
 	if (nor->addr_width > SPI_NOR_MAX_ADDR_WIDTH) {
@@ -3074,12 +3499,14 @@
 int spi_nor_scan(struct spi_nor *nor, const char *name,
 		 const struct spi_nor_hwcaps *hwcaps)
 {
-	const struct flash_info *info;
+	const struct flash_info *info = NULL;
 	struct device *dev = nor->dev;
 	struct mtd_info *mtd = &nor->mtd;
 	struct device_node *np = spi_nor_get_flash_node(nor);
 	int ret;
 	int i;
+	struct device_node *np_spi;
+	u32 is_dual;
 
 	ret = spi_nor_check(nor);
 	if (ret)
@@ -3125,7 +3552,11 @@
 	if (info->flags & SPI_NOR_HAS_LOCK)
 		nor->flags |= SNOR_F_HAS_LOCK;
 
-	mtd->_write = spi_nor_write;
+	/* sst nor chips use AAI word program */
+	if (info->flags & SST_WRITE)
+		mtd->_write = sst_write;
+	else
+		mtd->_write = spi_nor_write;
 
 	/* Init flash parameters based on flash_info struct and SFDP */
 	ret = spi_nor_init_params(nor);
@@ -3141,6 +3572,72 @@
 	mtd->size = nor->params->size;
 	mtd->_erase = spi_nor_erase;
 	mtd->_read = spi_nor_read;
+	nor->page_size = nor->params->page_size;
+#ifdef CONFIG_OF
+	np_spi = of_get_next_parent(np);
+	if (((of_property_match_string(np_spi, "compatible",
+				       "xlnx,zynq-qspi-1.0") >= 0) ||
+		(of_property_match_string(np_spi, "compatible",
+				"xlnx,zynqmp-qspi-1.0") >= 0)) ||
+		(of_property_match_string(np_spi, "compatible",
+				"xlnx,versal-qspi-1.0") >= 0) ||
+		(of_property_match_string(np_spi, "compatible",
+				"xlnx,versal-ospi-1.0") >= 0)) {
+		if (of_property_read_u32(np_spi, "is-dual",
+					 &is_dual) < 0) {
+			/* Default to single if prop not defined */
+			nor->shift = 0;
+			nor->isstacked = 0;
+			nor->isparallel = 0;
+		} else {
+			if (is_dual == 1) {
+				/* dual parallel */
+				nor->shift = 1;
+				nor->page_size = info->page_size << nor->shift;
+				mtd->size <<= nor->shift;
+				nor->isparallel = 1;
+				nor->isstacked = 0;
+				nor->spi->master->flags |=
+						(SPI_MASTER_DATA_STRIPE
+						| SPI_MASTER_BOTH_CS);
+			} else {
+#ifdef CONFIG_SPI_ZYNQ_QSPI_DUAL_STACKED
+				/* dual stacked */
+				nor->shift = 0;
+				mtd->size <<= 1;
+				nor->isstacked = 1;
+				nor->isparallel = 0;
+#else
+				u32 is_stacked;
+
+				if (of_property_read_u32(np_spi,
+							 "is-stacked",
+							 &is_stacked) < 0) {
+					is_stacked = 0;
+				}
+				if (is_stacked) {
+					/* dual stacked */
+					nor->shift = 0;
+					mtd->size <<= 1;
+					nor->isstacked = 1;
+					nor->isparallel = 0;
+				} else {
+					/* single */
+					nor->shift = 0;
+					nor->isstacked = 0;
+					nor->isparallel = 0;
+				}
+#endif
+			}
+		}
+	}
+#else
+	/* Default to single */
+	nor->shift = 0;
+	nor->isstacked = 0;
+	nor->isparallel = 0;
+#endif
+
 	mtd->_suspend = spi_nor_suspend;
 	mtd->_resume = spi_nor_resume;
 	mtd->_get_device = spi_nor_get_device;
@@ -3165,13 +3662,15 @@
 		nor->flags |= SNOR_F_HAS_4BIT_BP;
 		if (info->flags & SPI_NOR_BP3_SR_BIT6)
 			nor->flags |= SNOR_F_HAS_SR_BP3_BIT6;
+		else if (info->flags & SPI_NOR_BP3_SR_BIT5)
+			nor->flags |= SNOR_F_HAS_SR_BP3_BIT5;
 	}
 
 	if (info->flags & SPI_NOR_NO_ERASE)
 		mtd->flags |= MTD_NO_ERASE;
 
 	mtd->dev.parent = dev;
-	nor->page_size = nor->params->page_size;
+	nor->jedec_id = info->id[0];
 	mtd->writebufsize = nor->page_size;
 
 	if (of_property_read_bool(np, "broken-flash-reset"))
@@ -3311,8 +3810,12 @@
 	nor->dev = &spi->dev;
 	spi_nor_set_flash_node(nor, spi->dev.of_node);
 
+	if (nor->spimem)
+		init_completion(&nor->spimem->request_completion);
+
 	spi_mem_set_drvdata(spimem, nor);
 
+	nor->spi = spi;
 	if (data && data->name)
 		nor->mtd.name = data->name;
 
@@ -3377,6 +3880,9 @@
 {
 	struct spi_nor *nor = spi_mem_get_drvdata(spimem);
 
+	if (nor->addr_width == 3 &&
+	    (nor->mtd.size >> nor->shift) > 0x1000000)
+		spi_nor_write_ear(nor, 0);
 	spi_nor_restore(nor);
 }
 
--- linux-5.15.36/drivers/mtd/spi-nor/core.h	2023-04-14 12:26:01.615165300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/spi-nor/core.h	2023-04-14 12:24:08.702628500 +0900
@@ -29,6 +29,7 @@
 	SNOR_F_IO_MODE_EN_VOLATILE = BIT(14),
 	SNOR_F_SOFT_RESET	= BIT(15),
 	SNOR_F_SWP_IS_VOLATILE	= BIT(16),
+	SNOR_F_HAS_SR_BP3_BIT5  = BIT(17),
 };
 
 struct spi_nor_read_command {
@@ -382,6 +383,14 @@
 					 * protection bits. Usually these will
 					 * power-up in a write-protected state.
 					 */
+#define SST_GLOBAL_PROT_UNLK	BIT(24)	/* Unlock the Global protection for
+					 * sst flashes
+					 */
+#define SPI_NOR_BP3_SR_BIT5	BIT(25) /*
+					 * BP3 is bit 5 of status register.
+					 * Must be used with SPI_NOR_4BIT_BP.
+					 */
+	int	(*quad_enable)(struct spi_nor *nor);
 
 	const struct spi_nor_otp_organization otp_org;
 
@@ -498,7 +507,7 @@
 int spi_nor_write_enable(struct spi_nor *nor);
 int spi_nor_write_disable(struct spi_nor *nor);
 int spi_nor_set_4byte_addr_mode(struct spi_nor *nor, bool enable);
-int spi_nor_write_ear(struct spi_nor *nor, u8 ear);
+int spi_nor_write_ear(struct spi_nor *nor, u32 addr);
 int spi_nor_wait_till_ready(struct spi_nor *nor);
 int spi_nor_global_block_unlock(struct spi_nor *nor);
 int spi_nor_lock_and_prep(struct spi_nor *nor);
@@ -557,4 +566,7 @@
 	return mtd->priv;
 }
 
+int sst_write(struct mtd_info *mtd, loff_t to, size_t len,
+	      size_t *retlen, const u_char *buf);
+
 #endif /* __LINUX_MTD_SPI_NOR_INTERNAL_H */
--- linux-5.15.36/drivers/mtd/spi-nor/gigadevice.c	2023-04-14 12:26:01.615165300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/spi-nor/gigadevice.c	2023-04-14 12:24:08.702628500 +0900
@@ -8,6 +8,136 @@
 
 #include "core.h"
 
+#define SPINOR_OP_GD_DTR_RD	0xfd	/* Fast Read opcode in DTR mode */
+#define SPINOR_OP_GD_RD_ANY_REG	0x85	/* Read volatile register */
+#define SPINOR_OP_GD_WR_ANY_REG	0x81	/* Write volatile register */
+#define SPINOR_REG_GD_CFR0V	0x00	/* For setting octal DTR mode */
+#define SPINOR_REG_GD_CFR1V	0x01	/* For setting dummy cycles */
+#define SPINOR_GD_OCT_DTR	0xe7	/* Enable Octal DTR. */
+#define SPINOR_GD_EXSPI		0xff	/* Enable Extended SPI (default) */
+
+static int spi_nor_gigadevice_octal_dtr_enable(struct spi_nor *nor, bool enable)
+{
+	struct spi_mem_op op;
+	u8 *buf = nor->bouncebuf;
+	int ret;
+
+	if (enable) {
+		/* Use 20 dummy cycles for memory array reads. */
+		ret = spi_nor_write_enable(nor);
+		if (ret)
+			return ret;
+
+		*buf = 20;
+		op = (struct spi_mem_op)
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_GD_WR_ANY_REG, 1),
+				   SPI_MEM_OP_ADDR(3, SPINOR_REG_GD_CFR1V, 1),
+				   SPI_MEM_OP_NO_DUMMY,
+				   SPI_MEM_OP_DATA_OUT(1, buf, 1));
+
+		ret = spi_mem_exec_op(nor->spimem, &op);
+		if (ret)
+			return ret;
+
+		ret = spi_nor_wait_till_ready(nor);
+		if (ret)
+			return ret;
+	}
+
+	ret = spi_nor_write_enable(nor);
+	if (ret)
+		return ret;
+
+	if (enable)
+		*buf = SPINOR_GD_OCT_DTR;
+	else
+		*buf = SPINOR_GD_EXSPI;
+
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_GD_WR_ANY_REG, 1),
+			   SPI_MEM_OP_ADDR(enable ? 3 : 4,
+					   SPINOR_REG_GD_CFR0V, 1),
+			   SPI_MEM_OP_NO_DUMMY,
+			   SPI_MEM_OP_DATA_OUT(1, buf, 1));
+
+	if (!enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	if (nor->isstacked &&
+	    !(nor->spimem->spi->master->flags & SPI_MASTER_U_PAGE))
+		return 0;
+
+	/* Read flash ID to make sure the switch was successful. */
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDID, 1),
+			   SPI_MEM_OP_NO_ADDR,
+			   SPI_MEM_OP_DUMMY(enable ? 8 : 0, 1),
+			   SPI_MEM_OP_DATA_IN(round_up(nor->info->id_len, 2),
+					      buf, 1));
+
+	if (enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	if (memcmp(buf, nor->info->id, nor->info->id_len))
+		return -EINVAL;
+
+	return 0;
+}
+
+static int gd25lx256e_set_4byte_addr_mode(struct spi_nor *nor, bool enable)
+{
+	int ret;
+
+	ret = spi_nor_write_enable(nor);
+	if (ret)
+		return ret;
+
+	ret = spi_nor_set_4byte_addr_mode(nor, enable);
+	if (ret)
+		return ret;
+
+	return spi_nor_write_disable(nor);
+}
+
+static void gd25lx256e_default_init(struct spi_nor *nor)
+{
+	nor->params->octal_dtr_enable = spi_nor_gigadevice_octal_dtr_enable;
+	nor->params->set_4byte_addr_mode = gd25lx256e_set_4byte_addr_mode;
+}
+
+static void gd25lx256e_post_sfdp_fixup(struct spi_nor *nor)
+{
+	/* Set the Fast Read settings. */
+	nor->params->hwcaps.mask |= SNOR_HWCAPS_READ_8_8_8_DTR;
+	spi_nor_set_read_settings(&nor->params->reads[SNOR_CMD_READ_8_8_8_DTR],
+				  0, 20, SPINOR_OP_GD_DTR_RD,
+				  SNOR_PROTO_8_8_8_DTR);
+
+	nor->cmd_ext_type = SPI_NOR_EXT_REPEAT;
+	nor->params->rdsr_dummy = 8;
+	nor->params->rdsr_addr_nbytes = 0;
+
+	/*
+	 * The BFPT quad enable field is set to a reserved value so the quad
+	 * enable function is ignored by spi_nor_parse_bfpt(). Make sure we
+	 * disable it.
+	 */
+	nor->params->quad_enable = NULL;
+}
+
+static struct spi_nor_fixups gd25lx256e_fixups = {
+	.default_init = gd25lx256e_default_init,
+	.post_sfdp = gd25lx256e_post_sfdp_fixup,
+};
+
 static void gd25q256_default_init(struct spi_nor *nor)
 {
 	/*
@@ -50,6 +180,12 @@
 			   SPI_NOR_4B_OPCODES | SPI_NOR_HAS_LOCK |
 			   SPI_NOR_HAS_TB | SPI_NOR_TB_SR_BIT6)
 		.fixups = &gd25q256_fixups },
+	{ "gd25lx256e",  INFO(0xc86819, 0, 64 * 1024, 512,
+			      SECT_4K | USE_FSR | SPI_NOR_OCTAL_READ |
+			      SPI_NOR_4B_OPCODES | SPI_NOR_OCTAL_DTR_READ |
+			      SPI_NOR_OCTAL_DTR_PP |
+			      SPI_NOR_IO_MODE_EN_VOLATILE)
+		.fixups = &gd25lx256e_fixups },
 };
 
 const struct spi_nor_manufacturer spi_nor_gigadevice = {
--- linux-5.15.36/drivers/mtd/spi-nor/issi.c	2023-04-14 12:26:01.615165300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/spi-nor/issi.c	2023-04-14 12:24:08.702628500 +0900
@@ -8,6 +8,136 @@
 
 #include "core.h"
 
+#define SPINOR_OP_IS_DTR_RD	0xfd	/* Fast Read opcode in DTR mode */
+#define SPINOR_OP_IS_RD_ANY_REG	0x85	/* Read volatile register */
+#define SPINOR_OP_IS_WR_ANY_REG	0x81	/* Write volatile register */
+#define SPINOR_REG_IS_CFR0V	0x00	/* For setting octal DTR mode */
+#define SPINOR_REG_IS_CFR1V	0x01	/* For setting dummy cycles */
+#define SPINOR_IS_OCT_DTR	0xe7	/* Enable Octal DTR. */
+#define SPINOR_IS_EXSPI		0xff	/* Enable Extended SPI (default) */
+
+static int spi_nor_issi_octal_dtr_enable(struct spi_nor *nor, bool enable)
+{
+	struct spi_mem_op op;
+	u8 *buf = nor->bouncebuf;
+	int ret;
+
+	if (enable) {
+		/* Use 20 dummy cycles for memory array reads. */
+		ret = spi_nor_write_enable(nor);
+		if (ret)
+			return ret;
+
+		*buf = 20;
+		op = (struct spi_mem_op)
+			SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_IS_WR_ANY_REG, 1),
+				   SPI_MEM_OP_ADDR(3, SPINOR_REG_IS_CFR1V, 1),
+				   SPI_MEM_OP_NO_DUMMY,
+				   SPI_MEM_OP_DATA_OUT(1, buf, 1));
+
+		ret = spi_mem_exec_op(nor->spimem, &op);
+		if (ret)
+			return ret;
+
+		ret = spi_nor_wait_till_ready(nor);
+		if (ret)
+			return ret;
+	}
+
+	ret = spi_nor_write_enable(nor);
+	if (ret)
+		return ret;
+
+	if (enable)
+		*buf = SPINOR_IS_OCT_DTR;
+	else
+		*buf = SPINOR_IS_EXSPI;
+
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_IS_WR_ANY_REG, 1),
+			   SPI_MEM_OP_ADDR(enable ? 3 : 4,
+					   SPINOR_REG_IS_CFR0V, 1),
+			   SPI_MEM_OP_NO_DUMMY,
+			   SPI_MEM_OP_DATA_OUT(1, buf, 1));
+
+	if (!enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	if (nor->isstacked &&
+	    !(nor->spimem->spi->master->flags & SPI_MASTER_U_PAGE))
+		return 0;
+
+	/* Read flash ID to make sure the switch was successful. */
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDID, 1),
+			   SPI_MEM_OP_NO_ADDR,
+			   SPI_MEM_OP_DUMMY(enable ? 8 : 0, 1),
+			   SPI_MEM_OP_DATA_IN(round_up(nor->info->id_len, 2),
+					      buf, 1));
+
+	if (enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	if (memcmp(buf, nor->info->id, nor->info->id_len))
+		return -EINVAL;
+
+	return 0;
+}
+
+static int is25wx256_set_4byte_addr_mode(struct spi_nor *nor, bool enable)
+{
+	int ret;
+
+	ret = spi_nor_write_enable(nor);
+	if (ret)
+		return ret;
+
+	ret = spi_nor_set_4byte_addr_mode(nor, enable);
+	if (ret)
+		return ret;
+
+	return spi_nor_write_disable(nor);
+}
+
+static void is25wx256_default_init(struct spi_nor *nor)
+{
+	nor->params->octal_dtr_enable = spi_nor_issi_octal_dtr_enable;
+	nor->params->set_4byte_addr_mode = is25wx256_set_4byte_addr_mode;
+}
+
+static void is25wx256_post_sfdp_fixup(struct spi_nor *nor)
+{
+	/* Set the Fast Read settings. */
+	nor->params->hwcaps.mask |= SNOR_HWCAPS_READ_8_8_8_DTR;
+	spi_nor_set_read_settings(&nor->params->reads[SNOR_CMD_READ_8_8_8_DTR],
+				  0, 20, SPINOR_OP_IS_DTR_RD,
+				  SNOR_PROTO_8_8_8_DTR);
+
+	nor->cmd_ext_type = SPI_NOR_EXT_REPEAT;
+	nor->params->rdsr_dummy = 8;
+	nor->params->rdsr_addr_nbytes = 0;
+
+	/*
+	 * The BFPT quad enable field is set to a reserved value so the quad
+	 * enable function is ignored by spi_nor_parse_bfpt(). Make sure we
+	 * disable it.
+	 */
+	nor->params->quad_enable = NULL;
+}
+
+static struct spi_nor_fixups is25wx256_fixups = {
+	.default_init = is25wx256_default_init,
+	.post_sfdp = is25wx256_post_sfdp_fixup,
+};
+
 static int
 is25lp256_post_bfpt_fixups(struct spi_nor *nor,
 			   const struct sfdp_parameter_header *bfpt_header,
@@ -31,33 +161,67 @@
 
 static const struct flash_info issi_parts[] = {
 	/* ISSI */
+	{ "is25wp080d", INFO(0x9d7014, 0, 64 * 1024, 32, SECT_4K |
+		SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | SPI_NOR_HAS_LOCK) },
+	{ "is25wp016d", INFO(0x9d7015, 0, 64 * 1024, 32, SECT_4K |
+		SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | SPI_NOR_HAS_LOCK) },
 	{ "is25cd512",  INFO(0x7f9d20, 0, 32 * 1024,   2, SECT_4K) },
 	{ "is25lq040b", INFO(0x9d4013, 0, 64 * 1024,   8,
 			     SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ "is25lp016d", INFO(0x9d6015, 0, 64 * 1024,  32,
 			     SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ "is25lp080d", INFO(0x9d6014, 0, 64 * 1024,  16,
-			     SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+			SPI_NOR_HAS_LOCK) },
 	{ "is25lp032",  INFO(0x9d6016, 0, 64 * 1024,  64,
-			     SECT_4K | SPI_NOR_DUAL_READ) },
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_HAS_LOCK) },
 	{ "is25lp064",  INFO(0x9d6017, 0, 64 * 1024, 128,
-			     SECT_4K | SPI_NOR_DUAL_READ) },
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_HAS_LOCK) },
 	{ "is25lp128",  INFO(0x9d6018, 0, 64 * 1024, 256,
-			     SECT_4K | SPI_NOR_DUAL_READ) },
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_HAS_LOCK) },
 	{ "is25lp256",  INFO(0x9d6019, 0, 64 * 1024, 512,
 			     SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			     SPI_NOR_4B_OPCODES)
+			SPI_NOR_4B_OPCODES | SPI_NOR_HAS_LOCK |
+			SNOR_F_HAS_SR_BP3_BIT5)
 		.fixups = &is25lp256_fixups },
+	{ "is25wp256d", INFO(0x9d7019, 0, 64 * 1024, 512,
+			SECT_4K | SPI_NOR_DUAL_READ |
+			SPI_NOR_QUAD_READ | SPI_NOR_HAS_LOCK |
+			SPI_NOR_4B_OPCODES | SNOR_F_HAS_SR_BP3_BIT5) },
 	{ "is25wp032",  INFO(0x9d7016, 0, 64 * 1024,  64,
-			     SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+			SPI_NOR_HAS_LOCK) },
 	{ "is25wp064",  INFO(0x9d7017, 0, 64 * 1024, 128,
-			     SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ
+			 | SPI_NOR_HAS_LOCK) },
 	{ "is25wp128",  INFO(0x9d7018, 0, 64 * 1024, 256,
 			     SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ "is25wp256", INFO(0x9d7019, 0, 64 * 1024, 512,
 			    SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			    SPI_NOR_4B_OPCODES)
+			    SPI_NOR_4B_OPCODES | SNOR_F_HAS_SR_BP3_BIT5)
 		.fixups = &is25lp256_fixups },
+	{ "is25lp512m", INFO(0x9d601a, 0, 64 * 1024, 1024,
+			SECT_4K | SPI_NOR_DUAL_READ |
+			SPI_NOR_QUAD_READ | SPI_NOR_HAS_LOCK |
+			SNOR_F_HAS_SR_BP3_BIT5) },
+	{ "is25wp512m", INFO(0x9d701a, 0, 64 * 1024, 1024,
+			SECT_4K | SPI_NOR_DUAL_READ |
+			SPI_NOR_QUAD_READ | SPI_NOR_HAS_LOCK |
+			SPI_NOR_4B_OPCODES | SNOR_F_HAS_SR_BP3_BIT5) },
+	{ "is25lp01g", INFO(0x9d601b, 0, 64 * 1024, 2048,
+			SECT_4K | SPI_NOR_DUAL_READ |
+			SPI_NOR_QUAD_READ | SPI_NOR_HAS_LOCK |
+			SPI_NOR_4B_OPCODES | SNOR_F_HAS_SR_BP3_BIT5) },
+	{ "is25wp01g", INFO(0x9d701b, 0, 64 * 1024, 2048,
+			SECT_4K | SPI_NOR_DUAL_READ |
+			SPI_NOR_QUAD_READ | SPI_NOR_HAS_LOCK |
+			SPI_NOR_4B_OPCODES | SNOR_F_HAS_SR_BP3_BIT5) },
+	{ "is25wx256",  INFO(0x9d5b19, 0, 128 * 1024, 256,
+			     SECT_4K | USE_FSR | SPI_NOR_OCTAL_READ |
+			     SPI_NOR_4B_OPCODES | SPI_NOR_OCTAL_DTR_READ |
+			     SPI_NOR_OCTAL_DTR_PP |
+			     SPI_NOR_IO_MODE_EN_VOLATILE)
+		.fixups = &is25wx256_fixups },
 
 	/* PMC */
 	{ "pm25lv512",   INFO(0,        0, 32 * 1024,    2, SECT_4K_PMC) },
--- linux-5.15.36/drivers/mtd/spi-nor/macronix.c	2023-04-14 12:26:01.615165300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/spi-nor/macronix.c	2023-04-14 12:24:08.702628500 +0900
@@ -8,6 +8,134 @@
 
 #include "core.h"
 
+#define SPINOR_OP_MX_DTR_RD	0xee	/* Fast Read opcode in DTR mode */
+#define SPINOR_OP_MX_RD_ANY_REG	0x71	/* Read volatile register */
+#define SPINOR_OP_MX_WR_ANY_REG	0x72	/* Write volatile register */
+#define SPINOR_REG_MX_CFR0V	0x00	/* For setting octal DTR mode */
+#define SPINOR_MX_OCT_DTR	0x02	/* Enable Octal DTR. */
+#define SPINOR_MX_EXSPI		0x00	/* Enable Extended SPI (default) */
+
+static int spi_nor_macronix_octal_dtr_enable(struct spi_nor *nor, bool enable)
+{
+	struct spi_mem_op op;
+	u8 *buf = nor->bouncebuf;
+	int ret;
+
+	ret = spi_nor_write_enable(nor);
+	if (ret)
+		return ret;
+
+	if (enable)
+		*buf = SPINOR_MX_OCT_DTR;
+	else
+		*buf = SPINOR_MX_EXSPI;
+
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_MX_WR_ANY_REG, 1),
+			   SPI_MEM_OP_ADDR(4, SPINOR_REG_MX_CFR0V, 1),
+			   SPI_MEM_OP_NO_DUMMY,
+			   SPI_MEM_OP_DATA_OUT(1, buf, 1));
+
+	if (!enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	if (nor->isstacked &&
+	    !(nor->spimem->spi->master->flags & SPI_MASTER_U_PAGE))
+		return 0;
+
+	/* Read flash ID to make sure the switch was successful. */
+	op = (struct spi_mem_op)
+		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDID, 1),
+			   SPI_MEM_OP_ADDR(enable ? 4 : 0, 0, enable ? 1 : 0),
+			   SPI_MEM_OP_DUMMY(enable ? 4 : 0, 1),
+			   SPI_MEM_OP_DATA_IN(round_up(nor->info->id_len, 2),
+					      buf, 1));
+
+	if (enable)
+		spi_nor_spimem_setup_op(nor, &op, SNOR_PROTO_8_8_8_DTR);
+
+	ret = spi_mem_exec_op(nor->spimem, &op);
+	if (ret)
+		return ret;
+
+	if (enable) {
+		if (memcmp(buf, nor->spimem->device_id, nor->info->id_len))
+			return -EINVAL;
+	} else {
+		if (memcmp(buf, nor->info->id, nor->info->id_len))
+			return -EINVAL;
+	}
+
+	return 0;
+}
+
+static int mx25um51345g_set_4byte(struct spi_nor *nor, bool enable)
+{
+	(void)enable;
+
+	return 0;
+}
+
+static void mx25um51345g_default_init_fixups(struct spi_nor *nor)
+{
+	u8 id_byte1, id_byte2;
+	u32 sector_size = nor->info->sector_size;
+
+	nor->params->set_4byte_addr_mode = mx25um51345g_set_4byte;
+
+	/*
+	 * Macronix Read Id bytes are always output in STR mode. Since tuning
+	 * is based on Read Id command, adjust the Read Id bytes that will
+	 * match the Read Id output in DTR mode.
+	 */
+	id_byte1 = nor->spimem->device_id[1];
+	id_byte2 = nor->spimem->device_id[2];
+	nor->spimem->device_id[1] = nor->spimem->device_id[0];
+	nor->spimem->device_id[2] = id_byte1;
+	nor->spimem->device_id[3] = id_byte1;
+	nor->spimem->device_id[4] = id_byte2;
+	nor->spimem->device_id[5] = id_byte2;
+
+	if (nor->isparallel)
+		sector_size <<= 1;
+
+	spi_nor_set_erase_type(&nor->params->erase_map.erase_type[1],
+			       sector_size, SPINOR_OP_BE_4K_4B);
+	nor->params->page_programs[SNOR_CMD_PP_8_8_8_DTR].opcode =
+				SPINOR_OP_PP_4B;
+
+	nor->params->octal_dtr_enable = spi_nor_macronix_octal_dtr_enable;
+}
+
+static void mx25um51345g_post_sfdp_fixup(struct spi_nor *nor)
+{
+	/* Set the Fast Read settings. */
+	nor->params->hwcaps.mask |= SNOR_HWCAPS_READ_8_8_8_DTR;
+	spi_nor_set_read_settings(&nor->params->reads[SNOR_CMD_READ_8_8_8_DTR],
+				  0, 20, SPINOR_OP_MX_DTR_RD,
+				  SNOR_PROTO_8_8_8_DTR);
+
+	nor->cmd_ext_type = SPI_NOR_EXT_INVERT;
+	nor->params->rdsr_dummy = 8;
+	nor->params->rdsr_addr_nbytes = 0;
+
+	/*
+	 * The BFPT quad enable field is set to a reserved value so the quad
+	 * enable function is ignored by spi_nor_parse_bfpt(). Make sure we
+	 * disable it.
+	 */
+	nor->params->quad_enable = NULL;
+}
+
+static struct spi_nor_fixups mx25um51345g_fixups = {
+	.default_init = mx25um51345g_default_init_fixups,
+	.post_sfdp = mx25um51345g_post_sfdp_fixup,
+};
+
 static int
 mx25l25635_post_bfpt_fixups(struct spi_nor *nor,
 			    const struct sfdp_parameter_header *bfpt_header,
@@ -81,12 +209,27 @@
 			      SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
 	{ "mx66l1g45g",  INFO(0xc2201b, 0, 64 * 1024, 2048,
 			      SECT_4K | SPI_NOR_DUAL_READ |
-			      SPI_NOR_QUAD_READ) },
+			      SPI_NOR_QUAD_READ | SPI_NOR_HAS_LOCK |
+			      SPI_NOR_4BIT_BP) },
+	{ "mx66u1g45g",  INFO(0xc2253b, 0, 64 * 1024, 2048,
+			SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
+			SPI_NOR_HAS_LOCK | SPI_NOR_4BIT_BP) },
 	{ "mx66l1g55g",  INFO(0xc2261b, 0, 64 * 1024, 2048,
 			      SPI_NOR_QUAD_READ) },
+	{ "mx66l2g45g",	 INFO(0xc2201c, 0, 64 * 1024, 4096,
+			      SECT_4K | SPI_NOR_DUAL_READ |
+			      SPI_NOR_QUAD_READ | SPI_NOR_HAS_LOCK |
+			      SPI_NOR_4BIT_BP) },
 	{ "mx66u2g45g",	 INFO(0xc2253c, 0, 64 * 1024, 4096,
 			      SECT_4K | SPI_NOR_DUAL_READ |
-			      SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
+			      SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES |
+			      SPI_NOR_HAS_LOCK | SPI_NOR_4BIT_BP) },
+	{ "mx25um51345g",  INFO(0xc2813a, 0, 4 * 1024, 16384,
+				SECT_4K | SPI_NOR_OCTAL_READ |
+				SPI_NOR_4B_OPCODES | SPI_NOR_OCTAL_DTR_READ |
+				SPI_NOR_OCTAL_DTR_PP |
+				SPI_NOR_IO_MODE_EN_VOLATILE)
+		.fixups = &mx25um51345g_fixups },
 };
 
 static void macronix_default_init(struct spi_nor *nor)
--- linux-5.15.36/drivers/mtd/spi-nor/micron-st.c	2023-04-14 12:26:01.615165300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/spi-nor/micron-st.c	2023-04-14 12:24:08.702628500 +0900
@@ -67,6 +67,10 @@
 	if (ret)
 		return ret;
 
+	if (nor->isstacked &&
+	    !(nor->spimem->spi->master->flags & SPI_MASTER_U_PAGE))
+		return 0;
+
 	/* Read flash ID to make sure the switch was successful. */
 	op = (struct spi_mem_op)
 		SPI_MEM_OP(SPI_MEM_OP_CMD(SPINOR_OP_RDID, 1),
@@ -125,9 +129,18 @@
 			       SPI_NOR_OCTAL_DTR_PP |
 			       SPI_NOR_IO_MODE_EN_VOLATILE)
 	  .fixups = &mt35xu512aba_fixups},
+	{ "mt35xu01g", INFO(0x2c5b1b, 0, 128 * 1024, 1024,
+			    SECT_4K | USE_FSR | SPI_NOR_OCTAL_READ |
+			    SPI_NOR_4B_OPCODES | SPI_NOR_OCTAL_DTR_READ |
+			    SPI_NOR_OCTAL_DTR_PP |
+			    SPI_NOR_IO_MODE_EN_VOLATILE)
+	  .fixups = &mt35xu512aba_fixups},
 	{ "mt35xu02g", INFO(0x2c5b1c, 0, 128 * 1024, 2048,
 			    SECT_4K | USE_FSR | SPI_NOR_OCTAL_READ |
-			    SPI_NOR_4B_OPCODES) },
+			    SPI_NOR_4B_OPCODES | SPI_NOR_OCTAL_DTR_READ |
+			    SPI_NOR_OCTAL_DTR_PP |
+			    SPI_NOR_IO_MODE_EN_VOLATILE)
+	  .fixups = &mt35xu512aba_fixups},
 };
 
 static const struct flash_info st_parts[] = {
@@ -141,15 +154,13 @@
 			      SECT_4K | SPI_NOR_QUAD_READ) },
 	{ "n25q064a",    INFO(0x20bb17, 0, 64 * 1024,  128,
 			      SECT_4K | SPI_NOR_QUAD_READ) },
-	{ "n25q128a11",  INFO(0x20bb18, 0, 64 * 1024,  256,
-			      SECT_4K | USE_FSR | SPI_NOR_QUAD_READ |
-			      SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB |
-			      SPI_NOR_4BIT_BP | SPI_NOR_BP3_SR_BIT6) },
-	{ "n25q128a13",  INFO(0x20ba18, 0, 64 * 1024,  256,
-			      SECT_4K | USE_FSR | SPI_NOR_QUAD_READ) },
-	{ "mt25ql256a",  INFO6(0x20ba19, 0x104400, 64 * 1024,  512,
-			       SECT_4K | USE_FSR | SPI_NOR_DUAL_READ |
-			       SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
+	{ "n25q128a11",  INFO(0x20bb18, 0, 64 * 1024,  256, SECT_4K |
+			SPI_NOR_QUAD_READ | USE_FSR | SPI_NOR_HAS_LOCK) },
+	{ "n25q128a13",  INFO(0x20ba18, 0, 64 * 1024,  256, SECT_4K |
+			SPI_NOR_QUAD_READ | SPI_NOR_HAS_LOCK) },
+	{ "n25q256a",    INFO(0x20ba19, 0, 64 * 1024,  512, SECT_4K |
+			SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ | USE_FSR |
+			SPI_NOR_HAS_LOCK) },
 	{ "n25q256a",    INFO(0x20ba19, 0, 64 * 1024,  512, SECT_4K |
 			      USE_FSR | SPI_NOR_DUAL_READ |
 			      SPI_NOR_QUAD_READ) },
@@ -161,31 +172,29 @@
 	{ "mt25ql512a",  INFO6(0x20ba20, 0x104400, 64 * 1024, 1024,
 			       SECT_4K | USE_FSR | SPI_NOR_DUAL_READ |
 			       SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
-	{ "n25q512ax3",  INFO(0x20ba20, 0, 64 * 1024, 1024,
-			      SECT_4K | USE_FSR | SPI_NOR_QUAD_READ |
-			      SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB |
-			      SPI_NOR_4BIT_BP | SPI_NOR_BP3_SR_BIT6) },
+	{ "n25q512ax3",  INFO(0x20ba20, 0, 64 * 1024, 1024, SECT_4K |
+			USE_FSR | SPI_NOR_QUAD_READ | SPI_NOR_HAS_LOCK) },
 	{ "mt25qu512a",  INFO6(0x20bb20, 0x104400, 64 * 1024, 1024,
 			       SECT_4K | USE_FSR | SPI_NOR_DUAL_READ |
-			       SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES) },
+			       SPI_NOR_QUAD_READ | SPI_NOR_4B_OPCODES |
+				   SPI_NOR_HAS_LOCK) },
 	{ "n25q512a",    INFO(0x20bb20, 0, 64 * 1024, 1024,
 			      SECT_4K | USE_FSR | SPI_NOR_QUAD_READ |
 			      SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB |
 			      SPI_NOR_4BIT_BP | SPI_NOR_BP3_SR_BIT6) },
-	{ "n25q00",      INFO(0x20ba21, 0, 64 * 1024, 2048,
-			      SECT_4K | USE_FSR | SPI_NOR_QUAD_READ |
-			      SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB |
-			      SPI_NOR_4BIT_BP | SPI_NOR_BP3_SR_BIT6 |
-			      NO_CHIP_ERASE) },
-	{ "n25q00a",     INFO(0x20bb21, 0, 64 * 1024, 2048,
-			      SECT_4K | USE_FSR | SPI_NOR_QUAD_READ |
-			      NO_CHIP_ERASE) },
+	{ "n25q00",      INFO(0x20ba21, 0, 64 * 1024, 2048, SECT_4K |
+			USE_FSR | SPI_NOR_QUAD_READ | NO_CHIP_ERASE |
+			SPI_NOR_HAS_LOCK | SPI_NOR_HAS_LOCK) },
+	{ "n25q00a",     INFO(0x20bb21, 0, 64 * 1024, 2048, SECT_4K |
+			USE_FSR | SPI_NOR_QUAD_READ | NO_CHIP_ERASE |
+			SPI_NOR_HAS_LOCK) },
 	{ "mt25ql02g",   INFO(0x20ba22, 0, 64 * 1024, 4096,
 			      SECT_4K | USE_FSR | SPI_NOR_QUAD_READ |
-			      NO_CHIP_ERASE) },
+			      NO_CHIP_ERASE | SPI_NOR_HAS_LOCK) },
 	{ "mt25qu02g",   INFO(0x20bb22, 0, 64 * 1024, 4096,
 			      SECT_4K | USE_FSR | SPI_NOR_DUAL_READ |
-			      SPI_NOR_QUAD_READ | NO_CHIP_ERASE) },
+			      SPI_NOR_QUAD_READ | NO_CHIP_ERASE |
+				  SPI_NOR_HAS_LOCK) },
 
 	{ "m25p05",  INFO(0x202010,  0,  32 * 1024,   2, 0) },
 	{ "m25p10",  INFO(0x202011,  0,  32 * 1024,   4, 0) },
--- linux-5.15.36/drivers/mtd/spi-nor/sfdp.c	2023-04-14 12:26:01.615165300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/spi-nor/sfdp.c	2023-04-14 12:24:08.718249800 +0900
@@ -1378,9 +1378,16 @@
 		case SFDP_SECTOR_MAP_ID:
 			err = spi_nor_parse_smpt(nor, param_header);
 			break;
-
+#ifdef CONFIG_OF
 		case SFDP_4BAIT_ID:
-			err = spi_nor_parse_4bait(nor, param_header);
+			{
+				struct device_node *np = spi_nor_get_flash_node(nor);
+				struct device_node *np_spi = of_get_next_parent(np);
+
+				if (of_property_match_string(np_spi, "compatible",
+							     "xlnx,zynq-qspi-1.0") < 0)
+					err = spi_nor_parse_4bait(nor, param_header);
+			}
 			break;
 
 		case SFDP_PROFILE1_ID:
@@ -1390,7 +1397,7 @@
 		case SFDP_SCCR_MAP_ID:
 			err = spi_nor_parse_sccr(nor, param_header);
 			break;
-
+#endif
 		default:
 			break;
 		}
--- linux-5.15.36/drivers/mtd/spi-nor/spansion.c	2023-04-14 12:26:01.615165300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/spi-nor/spansion.c	2023-04-14 12:24:08.718249800 +0900
@@ -204,16 +204,16 @@
 			     SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ "s25fl128s0", INFO6(0x012018, 0x4d0080, 256 * 1024, 64,
 			      SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			      USE_CLSR) },
+			      USE_CLSR | SPI_NOR_HAS_LOCK) },
 	{ "s25fl128s1", INFO6(0x012018, 0x4d0180, 64 * 1024, 256,
 			      SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			      USE_CLSR) },
+			      USE_CLSR | SPI_NOR_HAS_LOCK) },
 	{ "s25fl256s0", INFO6(0x010219, 0x4d0080, 256 * 1024, 128,
 			      SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			      USE_CLSR) },
+			      USE_CLSR | SPI_NOR_HAS_LOCK) },
 	{ "s25fl256s1", INFO6(0x010219, 0x4d0180, 64 * 1024, 512,
 			      SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
-			      USE_CLSR) },
+			      USE_CLSR | SPI_NOR_HAS_LOCK) },
 	{ "s25fl512s",  INFO6(0x010220, 0x4d0080, 256 * 1024, 256,
 			      SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
 			      SPI_NOR_HAS_LOCK | USE_CLSR) },
@@ -278,13 +278,18 @@
 
 static void spansion_post_sfdp_fixups(struct spi_nor *nor)
 {
+	u32 sector_size = nor->info->sector_size;
+
 	if (nor->params->size <= SZ_16M)
 		return;
 
+	if (nor->isparallel)
+		sector_size <<= 1;
+
 	nor->flags |= SNOR_F_4B_OPCODES;
 	/* No small sector erase for 4-byte command set */
 	nor->erase_opcode = SPINOR_OP_SE;
-	nor->mtd.erasesize = nor->info->sector_size;
+	nor->mtd.erasesize = sector_size;
 }
 
 static const struct spi_nor_fixups spansion_fixups = {
--- linux-5.15.36/drivers/mtd/spi-nor/sst.c	2023-04-14 12:26:01.615165300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/spi-nor/sst.c	2023-04-14 12:24:08.718249800 +0900
@@ -81,18 +81,17 @@
 	{ "sst25wf080",  INFO(0xbf2505, 0, 64 * 1024, 16,
 			      SECT_4K | SST_WRITE | SPI_NOR_HAS_LOCK | SPI_NOR_SWP_IS_VOLATILE) },
 	{ "sst26wf016b", INFO(0xbf2651, 0, 64 * 1024, 32,
-			      SECT_4K | SPI_NOR_DUAL_READ |
-			      SPI_NOR_QUAD_READ) },
+			      SECT_4K | SST_GLOBAL_PROT_UNLK | SPI_NOR_SWP_IS_VOLATILE) },
 	{ "sst26vf016b", INFO(0xbf2641, 0, 64 * 1024, 32,
-			      SECT_4K | SPI_NOR_DUAL_READ) },
+			      SECT_4K | SST_GLOBAL_PROT_UNLK | SPI_NOR_SWP_IS_VOLATILE) },
 	{ "sst26vf064b", INFO(0xbf2643, 0, 64 * 1024, 128,
 			      SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ |
 			      SPI_NOR_HAS_LOCK | SPI_NOR_SWP_IS_VOLATILE)
 		.fixups = &sst26vf_fixups },
 };
 
-static int sst_write(struct mtd_info *mtd, loff_t to, size_t len,
-		     size_t *retlen, const u_char *buf)
+int sst_write(struct mtd_info *mtd, loff_t to, size_t len,
+	      size_t *retlen, const u_char *buf)
 {
 	struct spi_nor *nor = mtd_to_spi_nor(mtd);
 	size_t actual = 0;
--- linux-5.15.36/drivers/mtd/spi-nor/swp.c	2023-04-14 12:26:01.615165300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/spi-nor/swp.c	2023-04-14 12:24:08.718249800 +0900
@@ -16,6 +16,8 @@
 
 	if (nor->flags & SNOR_F_HAS_SR_BP3_BIT6)
 		return mask | SR_BP3_BIT6;
+	else if (nor->flags & SNOR_F_HAS_SR_BP3_BIT5)
+		return mask | SR_BP3_BIT5;
 
 	if (nor->flags & SNOR_F_HAS_4BIT_BP)
 		return mask | SR_BP3;
@@ -35,16 +37,24 @@
 {
 	unsigned int bp_slots, bp_slots_needed;
 	u8 mask = spi_nor_get_sr_bp_mask(nor);
+	u32 n_sectors = nor->info->n_sectors;
+	u32 sector_size = nor->info->sector_size;
+
+	if (nor->isstacked)
+		n_sectors <<= 1;
+
+	if (nor->isparallel)
+		sector_size <<= 1;
 
 	/* Reserved one for "protect none" and one for "protect all". */
 	bp_slots = (1 << hweight8(mask)) - 2;
-	bp_slots_needed = ilog2(nor->info->n_sectors);
+	bp_slots_needed = ilog2(n_sectors);
 
 	if (bp_slots_needed > bp_slots)
-		return nor->info->sector_size <<
+		return sector_size <<
 			(bp_slots_needed - bp_slots);
 	else
-		return nor->info->sector_size;
+		return sector_size;
 }
 
 static void spi_nor_get_locked_range_sr(struct spi_nor *nor, u8 sr, loff_t *ofs,
@@ -203,6 +213,9 @@
 
 		if (nor->flags & SNOR_F_HAS_SR_BP3_BIT6 && val & SR_BP3)
 			val = (val & ~SR_BP3) | SR_BP3_BIT6;
+		else if (nor->flags & SNOR_F_HAS_SR_BP3_BIT5 &&
+			 val & SR_BP3_BIT5)
+			val |= SR_BP3_BIT5;
 
 		if (val & ~mask)
 			return -EINVAL;
@@ -231,6 +244,26 @@
 	return spi_nor_write_sr_and_check(nor, status_new);
 }
 
+static bool spi_nor_is_lower_area(struct spi_nor *nor, loff_t ofs, uint64_t len)
+{
+	struct mtd_info *mtd = &nor->mtd;
+
+	if (nor->flags & SNOR_F_HAS_SR_TB)
+		return ((ofs + len) <= (mtd->size >> 1));
+	else
+		return false;
+}
+
+static bool spi_nor_is_upper_area(struct spi_nor *nor, loff_t ofs, uint64_t len)
+{
+	struct mtd_info *mtd = &nor->mtd;
+
+	if ((nor->flags & SNOR_F_HAS_SR_TB))
+		return (ofs >= (mtd->size >> 1));
+	else
+		return true;
+}
+
 /*
  * Unlock a region of the flash. See spi_nor_sr_lock() for more info
  *
@@ -259,12 +292,13 @@
 		return 0;
 
 	/* If anything below us is locked, we can't use 'top' protection */
-	if (!spi_nor_is_unlocked_sr(nor, 0, ofs, status_old))
+	if ((!spi_nor_is_unlocked_sr(nor, 0, ofs, status_old)) ||
+	    spi_nor_is_lower_area(nor, ofs, len))
 		can_be_top = false;
 
 	/* If anything above us is locked, we can't use 'bottom' protection */
 	if (!spi_nor_is_unlocked_sr(nor, ofs + len, mtd->size - (ofs + len),
-				    status_old))
+				    status_old) || spi_nor_is_upper_area(nor, ofs, len))
 		can_be_bottom = false;
 
 	if (!can_be_bottom && !can_be_top)
@@ -283,11 +317,14 @@
 		val = 0; /* fully unlocked */
 	} else {
 		min_prot_len = spi_nor_get_min_prot_length_sr(nor);
-		pow = ilog2(lock_len) - ilog2(min_prot_len) + 1;
+		pow = ilog2(mtd->size) - ilog2(min_prot_len) + 1;
 		val = pow << SR_BP_SHIFT;
 
 		if (nor->flags & SNOR_F_HAS_SR_BP3_BIT6 && val & SR_BP3)
 			val = (val & ~SR_BP3) | SR_BP3_BIT6;
+		else if (nor->flags & SNOR_F_HAS_SR_BP3_BIT5 &&
+			 val & SR_BP3_BIT5)
+			val |= SR_BP3_BIT5;
 
 		/* Some power-of-two sizes are not supported */
 		if (val & ~mask)
@@ -343,17 +380,181 @@
 	nor->params->locking_ops = &spi_nor_sr_locking_ops;
 }
 
+static int write_sr_modify_protection(struct spi_nor *nor, u8 status,
+				      u8 lock_bits)
+{
+	u8 status_new, bp_mask;
+
+	status_new = status & ~SR_BP_BIT_MASK;
+	bp_mask = (lock_bits << SR_BP_BIT_OFFSET) & SR_BP_BIT_MASK;
+
+	/* Micron */
+	if (nor->jedec_id == CFI_MFR_ST) {
+		/* To support chips with more than 896 sectors (56MB) */
+		status_new &= ~SR_BP3;
+
+		/* Protected area starts from top */
+		status_new &= ~SR_BP_TB;
+
+		if (lock_bits > 7)
+			bp_mask |= SR_BP3;
+	} else if (nor->jedec_id == CFI_MFR_WINBND) { /* Winbond */
+		status_new &= ~SR_BP3_BIT5;
+
+		/* Protected area starts from top */
+		status_new &= ~SR_BP_TB;
+
+		if (lock_bits > 7)
+			bp_mask |= SR_BP3_BIT5;
+	/* ISSI */
+	/* Macronix */
+	} else if (nor->jedec_id == CFI_MFR_PMC ||
+		   nor->jedec_id == CFI_MFR_MACRONIX) {
+		status_new &= ~SR_BP3_BIT5;
+
+		if (lock_bits > 7)
+			bp_mask |= SR_BP3_BIT5;
+	}
+
+	if (nor->is_lock)
+		status_new |= bp_mask;
+
+	/* For spansion flashes */
+	if (nor->jedec_id == CFI_MFR_AMD) {
+		spi_nor_read_cr(nor, &nor->bouncebuf[1]);
+		nor->bouncebuf[0] = status_new;
+		if (spi_nor_write_sr(nor, nor->bouncebuf, 2) < 0)
+			return 1;
+	} else {
+		nor->bouncebuf[0] = status_new;
+		if (spi_nor_write_sr(nor, &nor->bouncebuf[0], 1) < 0)
+			return 1;
+	}
+	return 0;
+}
+
+static u8 bp_bits_from_sr(struct spi_nor *nor, u8 status)
+{
+	u8 ret;
+
+	ret = (((status) & SR_BP_BIT_MASK) >> SR_BP_BIT_OFFSET);
+	if (nor->jedec_id == 0x20)
+		ret |= ((status & SR_BP3) >> (SR_BP_BIT_OFFSET + 1));
+	else if ((nor->jedec_id == CFI_MFR_WINBND) &&
+		 (nor->flags & SNOR_F_HAS_4BIT_BP))
+		ret |= ((status & SR_BP3_BIT5) >> SR_BP_BIT_OFFSET);
+	else if (nor->jedec_id == CFI_MFR_PMC ||	/* ISSI */
+		 nor->jedec_id == CFI_MFR_MACRONIX)	/* Macronix */
+		ret |= ((status & SR_BP3_BIT5) >> SR_BP_BIT_OFFSET);
+
+	return ret;
+}
+
+static inline u16 min_lockable_sectors(struct spi_nor *nor,
+				       u16 n_sectors)
+{
+	u16 lock_granularity;
+
+	/*
+	 * Revisit - SST (not used by us) has the same JEDEC ID as micron but
+	 * protected area table is similar to that of spansion.
+	 */
+	lock_granularity = max(1, n_sectors / M25P_MAX_LOCKABLE_SECTORS);
+	if (nor->jedec_id == CFI_MFR_ST ||	/* Micron */
+	    nor->jedec_id == CFI_MFR_PMC ||	/* ISSI */
+	    nor->jedec_id == CFI_MFR_MACRONIX)	/* Macronix */
+		lock_granularity = 1;
+
+	return lock_granularity;
+}
+
+static inline uint32_t get_protected_area_start(struct spi_nor *nor,
+						u8 lock_bits)
+{
+	u16 n_sectors;
+	u32 sector_size;
+	u64 mtd_size;
+	struct mtd_info *mtd = &nor->mtd;
+
+	n_sectors = nor->n_sectors;
+	sector_size = nor->sector_size;
+	mtd_size = mtd->size;
+
+	if (nor->isparallel) {
+		sector_size = (nor->sector_size >> 1);
+		mtd_size = (mtd->size >> 1);
+	}
+	if (nor->isstacked) {
+		n_sectors = (nor->n_sectors >> 1);
+		mtd_size = (mtd->size >> 1);
+	}
+
+	return mtd_size - (1 << (lock_bits - 1)) *
+		min_lockable_sectors(nor, n_sectors) * sector_size;
+}
+
+static u8 min_protected_area_including_offset(struct spi_nor *nor,
+					      uint32_t offset)
+{
+	u8 lock_bits, lockbits_limit;
+
+	/*
+	 * Revisit - SST (not used by us) has the same JEDEC ID as micron but
+	 * protected area table is similar to that of spansion.
+	 * Mircon has 4 block protect bits.
+	 */
+	lockbits_limit = 7;
+	if (nor->jedec_id == CFI_MFR_ST ||	/* Micron */
+	    nor->jedec_id == CFI_MFR_PMC ||	/* ISSI */
+	    nor->jedec_id == CFI_MFR_MACRONIX)	/* Macronix */
+		lockbits_limit = 15;
+
+	for (lock_bits = 1; lock_bits < lockbits_limit; lock_bits++) {
+		if (offset >= get_protected_area_start(nor, lock_bits))
+			break;
+	}
+	return lock_bits;
+}
+
 static int spi_nor_lock(struct mtd_info *mtd, loff_t ofs, uint64_t len)
 {
 	struct spi_nor *nor = mtd_to_spi_nor(mtd);
 	int ret;
+	u8 lock_bits;
 
 	ret = spi_nor_lock_and_prep(nor);
 	if (ret)
 		return ret;
 
+	if (nor->isparallel == 1)
+		ofs = ofs >> nor->shift;
+
+	if (nor->isstacked == 1) {
+		if (ofs >= (mtd->size / 2)) {
+			ofs = ofs - (mtd->size / 2);
+			nor->spimem->spi->master->flags |= SPI_MASTER_U_PAGE;
+		} else {
+			nor->spimem->spi->master->flags &= ~SPI_MASTER_U_PAGE;
+		}
+	}
 	ret = nor->params->locking_ops->lock(nor, ofs, len);
+	/* Wait until finished previous command */
+	ret = spi_nor_wait_till_ready(nor);
+	if (ret)
+		goto err;
 
+	ret = spi_nor_read_sr(nor, nor->bouncebuf);
+
+	lock_bits = min_protected_area_including_offset(nor, ofs);
+
+	/* Only modify protection if it will not unlock other areas */
+	if (lock_bits > bp_bits_from_sr(nor, nor->bouncebuf[0])) {
+		nor->is_lock = 1;
+		ret = write_sr_modify_protection(nor, nor->bouncebuf[0], lock_bits);
+	} else {
+		dev_err(nor->dev, "trying to unlock already locked area\n");
+	}
+err:
 	spi_nor_unlock_and_unprep(nor);
 	return ret;
 }
@@ -362,13 +563,40 @@
 {
 	struct spi_nor *nor = mtd_to_spi_nor(mtd);
 	int ret;
+	u8 lock_bits;
 
 	ret = spi_nor_lock_and_prep(nor);
 	if (ret)
 		return ret;
 
+	if (nor->isparallel == 1)
+		ofs = ofs >> nor->shift;
+
+	if (nor->isstacked == 1) {
+		if (ofs >= (mtd->size / 2)) {
+			ofs = ofs - (mtd->size / 2);
+			nor->spimem->spi->master->flags |= SPI_MASTER_U_PAGE;
+		} else {
+			nor->spimem->spi->master->flags &= ~SPI_MASTER_U_PAGE;
+		}
+	}
 	ret = nor->params->locking_ops->unlock(nor, ofs, len);
+	/* Wait until finished previous command */
+	ret = spi_nor_wait_till_ready(nor);
+	if (ret)
+		goto err;
 
+	ret = spi_nor_read_sr(nor, nor->bouncebuf);
+
+	lock_bits = min_protected_area_including_offset(nor, ofs + len) - 1;
+	/* Only modify protection if it will not lock other areas */
+	if (lock_bits < bp_bits_from_sr(nor, nor->bouncebuf[0])) {
+		nor->is_lock = 0;
+		ret = write_sr_modify_protection(nor, nor->bouncebuf[0], lock_bits);
+	} else {
+		dev_err(nor->dev, "trying to lock already unlocked area\n");
+	}
+err:
 	spi_nor_unlock_and_unprep(nor);
 	return ret;
 }
@@ -388,6 +616,26 @@
 	return ret;
 }
 
+static void spi_nor_prot_unlock(struct spi_nor *nor)
+{
+	if (nor->info->flags & SST_GLOBAL_PROT_UNLK) {
+		spi_nor_write_enable(nor);
+		if (nor->spimem) {
+			struct spi_mem_op op =
+				SPI_MEM_OP(SPI_MEM_OP_CMD(GLOBAL_BLKPROT_UNLK, 1),
+					   SPI_MEM_OP_NO_ADDR,
+					   SPI_MEM_OP_NO_DUMMY,
+					   SPI_MEM_OP_NO_DATA);
+
+			spi_mem_exec_op(nor->spimem, &op);
+		} else {
+			/* Unlock global write protection bits */
+			nor->controller_ops->write_reg(nor, GLOBAL_BLKPROT_UNLK, NULL, 0);
+		}
+	}
+	spi_nor_wait_till_ready(nor);
+}
+
 /**
  * spi_nor_try_unlock_all() - Tries to unlock the entire flash memory array.
  * @nor:	pointer to a 'struct spi_nor'.
@@ -403,15 +651,20 @@
 void spi_nor_try_unlock_all(struct spi_nor *nor)
 {
 	int ret;
+	const struct flash_info *info = nor->info;
 
-	if (!(nor->flags & SNOR_F_HAS_LOCK))
-		return;
-
-	dev_dbg(nor->dev, "Unprotecting entire flash array\n");
-
-	ret = spi_nor_unlock(&nor->mtd, 0, nor->params->size);
-	if (ret)
-		dev_dbg(nor->dev, "Failed to unlock the entire flash memory array\n");
+	if (nor->jedec_id == CFI_MFR_ATMEL ||
+	    nor->jedec_id == CFI_MFR_INTEL ||
+	    nor->jedec_id == CFI_MFR_SST ||
+	    nor->flags & SNOR_F_HAS_LOCK) {
+		if (info->flags & SST_GLOBAL_PROT_UNLK) {
+			spi_nor_prot_unlock(nor);
+		} else {
+			ret = spi_nor_unlock(&nor->mtd, 0, nor->params->size);
+			if (ret)
+				dev_dbg(nor->dev, "Failed to unlock the entire flash memory array\n");
+		}
+	}
 }
 
 void spi_nor_register_locking_ops(struct spi_nor *nor)
--- linux-5.15.36/drivers/mtd/spi-nor/winbond.c	2023-04-14 12:26:01.615165300 +0900
+++ linux-xlnx-2022.2/drivers/mtd/spi-nor/winbond.c	2023-04-14 12:24:08.718249800 +0900
@@ -100,6 +100,11 @@
 			     SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 	{ "w25m512jv", INFO(0xef7119, 0, 64 * 1024, 1024,
 			    SECT_4K | SPI_NOR_QUAD_READ | SPI_NOR_DUAL_READ) },
+	{ "w25h02jv", INFO(0xef9022, 0, 64 * 1024, 4096,
+			    SECT_4K | SPI_NOR_QUAD_READ | SPI_NOR_DUAL_READ |
+			    SPI_NOR_HAS_LOCK | SPI_NOR_HAS_TB |
+			    SPI_NOR_TB_SR_BIT6 | SPI_NOR_4BIT_BP |
+			    SPI_NOR_BP3_SR_BIT5 | SPI_NOR_4B_OPCODES) },
 	{ "w25q512jvq", INFO(0xef4020, 0, 64 * 1024, 1024,
 			     SECT_4K | SPI_NOR_DUAL_READ | SPI_NOR_QUAD_READ) },
 };
--- linux-5.15.36/drivers/mtd/tests/speedtest.c	2023-04-14 12:26:01.630784500 +0900
+++ linux-xlnx-2022.2/drivers/mtd/tests/speedtest.c	2023-04-14 12:24:08.718249800 +0900
@@ -160,14 +160,13 @@
 
 static long calc_speed(void)
 {
-	uint64_t k;
-	long ms;
+	uint64_t k, us;
 
-	ms = ktime_ms_delta(finish, start);
-	if (ms == 0)
+	us = ktime_us_delta(finish, start);
+	if (us == 0)
 		return 0;
-	k = (uint64_t)goodebcnt * (mtd->erasesize / 1024) * 1000;
-	do_div(k, ms);
+	k = (uint64_t)goodebcnt * (mtd->erasesize / 1024) * 1000000;
+	do_div(k, us);
 	return k;
 }
 
